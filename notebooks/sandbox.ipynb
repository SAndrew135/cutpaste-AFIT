{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "118cbde3-2a60-407e-8011-44f6e0cd273b",
   "metadata": {},
   "source": [
    "# Notes from video chat on June 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "90e20644-7746-4d78-9f63-e5dccddb4378",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 Filters Results: \n",
      "Epoch 1/10\n",
      "175/175 [==============================] - ETA: 0s - loss: 0.6968 - accuracy: 0.4994"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-44-09a7befff137>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    203\u001b[0m       \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mepoch_number\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    204\u001b[0m       \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m11200\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 205\u001b[0;31m       \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_gen\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    206\u001b[0m     )\n\u001b[1;32m    207\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     64\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m     \u001b[0;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m    870\u001b[0m               \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    871\u001b[0m               \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 872\u001b[0;31m               return_dict=True)\n\u001b[0m\u001b[1;32m    873\u001b[0m           \u001b[0mval_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'val_'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mval\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mval_logs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    874\u001b[0m           \u001b[0mepoch_logs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_logs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     64\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m     \u001b[0;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(self, x, y, batch_size, verbose, sample_weight, steps, callbacks, max_queue_size, workers, use_multiprocessing, return_dict)\u001b[0m\n\u001b[1;32m   1079\u001b[0m                 step_num=step):\n\u001b[1;32m   1080\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_test_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1081\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1082\u001b[0m               \u001b[0;31m# Catch OutOfRangeError for Datasets of unknown size.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1083\u001b[0m               \u001b[0;31m# This blocks until the batch has finished executing.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    578\u001b[0m         \u001b[0mxla_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    579\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 580\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    581\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    582\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    616\u001b[0m       \u001b[0;31m# In this case we have not created variables on the first call. So we can\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    617\u001b[0m       \u001b[0;31m# run the first trace but we should fail if variables are created.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 618\u001b[0;31m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    619\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_created_variables\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    620\u001b[0m         raise ValueError(\"Creating variables on a non-first call to a function\"\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2418\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2419\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2420\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2421\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2422\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   1663\u001b[0m          if isinstance(t, (ops.Tensor,\n\u001b[1;32m   1664\u001b[0m                            resource_variable_ops.BaseResourceVariable))),\n\u001b[0;32m-> 1665\u001b[0;31m         self.captured_inputs)\n\u001b[0m\u001b[1;32m   1666\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1667\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1744\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1745\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1746\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1747\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1748\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    596\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    597\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 598\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    599\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    600\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import importlib\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import random\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Dense, Flatten, GaussianNoise\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import pandas as pd\n",
    "\n",
    "notebooks_dir = os.path.abspath('')\n",
    "proj_dir = os.path.dirname(notebooks_dir)\n",
    "raw_data_dir = os.path.join(proj_dir, 'raw_data')\n",
    "src_dir = os.path.join(proj_dir, 'src')\n",
    "\n",
    "# Add src_dir to the system path to import helper file\n",
    "sys.path.insert(1, src_dir)\n",
    "#import cutpaste_helper\n",
    "#importlib.reload(cutpaste_helper)\n",
    "\n",
    "def makeWindows(image_dict,num_windows, width, height):\n",
    "    '''\n",
    "    Parameters:\n",
    "    image_dict: dictionary containing arrays that represent images\n",
    "    num_windows: the number of windows wanted\n",
    "    width: the width of the window\n",
    "    height: the height of the window\n",
    "    '''\n",
    "    \n",
    "    #store the coordinates of the defective window\n",
    "    \n",
    "    #Grab windows from the full images from train images\n",
    "    window_images = []\n",
    "    for key in image_dict:\n",
    "    #The 100 windows per image in a list\n",
    "        for i in range(0, num_windows):\n",
    "            #Get the width and height of an image\n",
    "            dimensions = image_dict[key].shape\n",
    "            image_w = dimensions[1]\n",
    "            image_h = dimensions[0]\n",
    "            #Random coordinates\n",
    "            random_x_coord = random.randint(0, image_w - width)\n",
    "            random_y_coord = random.randint(0, image_h-height)\n",
    "            #Takes window out of a random part of the images at the random coordinates\n",
    "            window = image_dict[key][random_y_coord:random_y_coord + window_y, random_x_coord:random_x_coord + window_x]\n",
    "            window_images.append(window)\n",
    "    window_images = np.array(window_images)\n",
    "    return window_images\n",
    "\n",
    "def makeDefects(window_list):\n",
    "    #Create test window images dict with white square defects\n",
    "    defect_window_list = np.copy(window_list)\n",
    "#Fill defect train window images\n",
    "    for image in defect_window_list:\n",
    "        #Random sized white square (2D array full of ones)\n",
    "        sq_random_x = random.randint(5,25)\n",
    "        sq_random_y = random.randint(5,25)\n",
    "        white_square = np.ones((sq_random_y,sq_random_x))\n",
    "        #Random coordinates for the square\n",
    "        random_x_coord = random.randint(0,window_x-sq_random_x)\n",
    "        random_y_coord = random.randint(0,window_y-sq_random_y)\n",
    "        #Replace the coordinates with white square\n",
    "        image[random_y_coord:random_y_coord + sq_random_y, random_x_coord: random_x_coord + sq_random_x,0] = white_square\n",
    "    return defect_window_list\n",
    "\n",
    "def copyPaste(window_list):\n",
    "    defect_window_list = np.copy(window_list)\n",
    "    #Fill defect train window images\n",
    "    for window in defect_window_list:\n",
    "        #Random sized copy-pasted area (2D array)\n",
    "        sq_random_x = random.randint(5,25)\n",
    "        sq_random_y = random.randint(5,25)\n",
    "        #Random coordinates for the square\n",
    "        random_x_coord = random.randint(0,window.shape[1]-sq_random_x)\n",
    "        random_y_coord = random.randint(0,window.shape[0]-sq_random_y)\n",
    "        #Copy the area\n",
    "        copyArea = window[random_y_coord:random_y_coord + sq_random_y, random_x_coord: random_x_coord + sq_random_x,0]\n",
    "        #Paste coordinates\n",
    "        random_x_coord = random.randint(0,window_x-sq_random_x)\n",
    "        random_y_coord = random.randint(0,window_y-sq_random_y)\n",
    "        #Paste the area\n",
    "        window[random_y_coord:random_y_coord + sq_random_y, random_x_coord: random_x_coord + sq_random_x,0] = copyArea\n",
    "    return defect_window_list\n",
    "\n",
    "def createLabels(image_list, defect_status):\n",
    "    #Create labels for the images\n",
    "    labels_list = []\n",
    "    for image in image_list:\n",
    "        if defect_status:\n",
    "            labels_list.append(1)\n",
    "        else:\n",
    "            labels_list.append(0)\n",
    "    labels_list = np.array(labels_list)\n",
    "    return labels_list\n",
    "        \n",
    "def shuffleTwoArrays(image_list, label_list):\n",
    "    #Shuffles the image and label arrays in the same way\n",
    "    randomize = np.arange(len(label_list))\n",
    "    np.random.shuffle(randomize)\n",
    "    image_list = image_list[randomize]\n",
    "    label_list = label_list[randomize]\n",
    "    return (image_list, label_list)\n",
    "\n",
    "def generateImages(normal_image_list, defect_image_list, num_normal, num_defects):\n",
    "    \n",
    "    while True:\n",
    "        #A generator that generates noise for all images\n",
    "        generated_images = []\n",
    "        generated_labels = []\n",
    "        for i in range(num_normal):\n",
    "            random_index = random.randint(0,len(normal_image_list)-1)\n",
    "            generated_images.append(normal_image_list[random_index])\n",
    "            generated_labels.append(0)\n",
    "        for i in range(num_defects):\n",
    "            random_index = random.randint(0,len(defect_image_list)-1)\n",
    "            generated_images.append(defect_image_list[random_index])\n",
    "            generated_labels.append(1)\n",
    "        generated_images = np.array(generated_images)\n",
    "        generated_labels = np.array(generated_labels)\n",
    "        generated_images, generated_labels = shuffleTwoArrays(generated_images, generated_labels)\n",
    "        n = generated_images.shape[0]\n",
    "        \n",
    "        yield generated_images, generated_labels.reshape(n, 1)\n",
    "        \n",
    "def valGeneratorImages(test_x, test_y):\n",
    "    while True:\n",
    "        yield test_x, test_y\n",
    "\n",
    "    \n",
    "# Load dictionaries with TEM images\n",
    "f_name = os.path.join(raw_data_dir, 'test_full_arrays')\n",
    "#Dict with test image arrays (each key has a value of an array of numbers between 0 and 1)\n",
    "test_full_arrays = pickle.load(open(f_name, \"rb\"))\n",
    "f_name = os.path.join(raw_data_dir, 'train_full_arrays')\n",
    "#Dict with train image arrays (each key has a value of an array of numbers between 0 and 1)\n",
    "train_full_arrays = pickle.load(open(f_name, \"rb\"))\n",
    "\n",
    "window_x = 118\n",
    "window_y = 84\n",
    "num_windows = 100\n",
    "\n",
    "#Make testing window images and labels\n",
    "test_window_images = makeWindows(test_full_arrays, num_windows, window_x, window_y)\n",
    "test_window_labels = createLabels(test_window_images, False)\n",
    "\n",
    "#Make training window images and labels\n",
    "train_window_images = makeWindows(train_full_arrays, num_windows ,window_x, window_y)\n",
    "train_window_labels = createLabels(train_window_images, False)\n",
    "\n",
    "#Make defect testing window images and labels\n",
    "defect_test_window_images = copyPaste(test_window_images)\n",
    "defect_test_window_labels = createLabels(defect_test_window_images, True)\n",
    "\n",
    "#Make defect training window images and labels\n",
    "defect_train_window_images = copyPaste(train_window_images)\n",
    "defect_train_window_labels = createLabels(defect_train_window_images, True)\n",
    "        \n",
    "# #Put all testing & training images and labels in one list each and making them random\n",
    "# all_training_images = np.concatenate((train_window_images, defect_train_window_images), axis = 0)\n",
    "# all_training_labels = np.concatenate((train_window_labels, defect_train_window_labels), axis = 0)\n",
    "# training_images, training_labels = shuffleTwoArrays(all_training_images, all_training_labels)\n",
    "all_testing_images = np.concatenate((test_window_images, defect_test_window_images), axis = 0)\n",
    "all_testing_labels = np.concatenate((test_window_labels, defect_test_window_labels), axis = 0)\n",
    "testing_images, testing_labels = shuffleTwoArrays(all_testing_images, all_testing_labels)\n",
    "\n",
    "#Stuff\n",
    "# filters = [4,8,16,32]\n",
    "filters = [4]\n",
    "filter_size = 3\n",
    "pool_size = 2\n",
    "epoch_number = 10\n",
    "my_models = []\n",
    "my_val_accuracy = []\n",
    "my_val_loss = []\n",
    "\n",
    "# Build the model.\n",
    "for filter_num in filters:\n",
    "    print(f'{filter_num} Filters Results: ')\n",
    "    train_gen = generateImages(train_window_images, defect_train_window_images, 32, 32)\n",
    "    val_gen = generateImages(test_window_images, defect_test_window_images, 128, 128)\n",
    "    model = Sequential([\n",
    "      GaussianNoise(1.),\n",
    "      Conv2D(filter_num, filter_size),\n",
    "      MaxPooling2D(pool_size=pool_size),\n",
    "      Conv2D(filter_num * 2, filter_size),\n",
    "      MaxPooling2D(pool_size = pool_size),\n",
    "      Conv2D(filter_num, filter_size),\n",
    "      MaxPooling2D(pool_size=pool_size),\n",
    "      Conv2D(filter_num * 4, filter_size),\n",
    "      MaxPooling2D(pool_size = pool_size),\n",
    "      Flatten(),\n",
    "      Dense(2, activation='softmax'),\n",
    "    ])\n",
    "\n",
    "    # Compile the model.\n",
    "    model.compile(\n",
    "      'adam',\n",
    "      loss='categorical_crossentropy',\n",
    "      metrics=['accuracy'],\n",
    "    )\n",
    "\n",
    "    # Train the model.\n",
    "    history = model.fit(\n",
    "      train_gen,\n",
    "      epochs = epoch_number,\n",
    "      steps_per_epoch=11200/64,\n",
    "      validation_data=val_gen\n",
    "    )\n",
    "\n",
    "#     # Predict on the first 5 test images.\n",
    "#     predictions = model.predict(testing_images[:5])\n",
    "\n",
    "#     # Print our model's predictions.\n",
    "#     print(\"Predictions\")\n",
    "#     print(np.argmax(predictions, axis=1))\n",
    "\n",
    "#     # Check our predictions against the ground truths.\n",
    "#     print(\"Real Labels\")\n",
    "#     print(testing_labels[:5])\n",
    "    \n",
    "#     my_models.append(model)\n",
    "#     my_val_accuracy.append(history.history['val_accuracy'][-1])\n",
    "#     my_val_loss.append(history.history['val_loss'][-1])\n",
    "    \n",
    "# #Saves the models and model metrics to a dataframe, then saves the dataframe to a csv file and a excel file\n",
    "# d = {'Models' : my_models, 'Value Accuracy' : my_val_accuracy, 'Value Loss' : my_val_loss}\n",
    "# df = pd.DataFrame(data=d, index=filters)\n",
    "# df.to_csv(r'C:\\Users\\songa\\Cutpaste Work\\project_cutpaste\\CSV files\\White Square Dataframe', index=False)\n",
    "# df.to_excel(r'C:\\Users\\songa\\Cutpaste Work\\project_cutpaste\\CSV files\\White Square Dataframe.xlsx', index=False)\n",
    "# display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "44eb7b33-aeba-49cb-9f4b-d74be9a08a47",
   "metadata": {},
   "outputs": [],
   "source": [
    "gen = generateImages(train_window_images, defect_train_window_images, 32, 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "d0ff770c-8bb7-4605-b32c-48132b44e5ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(256, 84, 118, 1)\n",
      "(256,)\n",
      "[0 0 0 1 1]\n"
     ]
    }
   ],
   "source": [
    "images, labels = next(val_gen)\n",
    "print(np.shape(images))\n",
    "print(np.shape(labels))\n",
    "print(labels[0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "eae2619b-8834-453f-ae57-c3a5296c2878",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<generator object generateImages at 0x7fce50261cd0>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_gen"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
