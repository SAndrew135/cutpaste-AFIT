{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "eafa15d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import importlib\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import random\n",
    "import numpy as np\n",
    "from keras import layers\n",
    "from tensorflow.keras.models import Sequential\n",
    "from keras.layers import Input, Add, Dense, Activation, ZeroPadding2D, BatchNormalization, Flatten, Conv2D, AveragePooling2D, MaxPooling2D\n",
    "from keras.models import Model, load_model\n",
    "from keras.initializers import glorot_uniform\n",
    "from keras.utils import plot_model\n",
    "from IPython.display import SVG\n",
    "from keras.utils.vis_utils import model_to_dot\n",
    "import keras.backend as K\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.framework import ops\n",
    "from tensorflow.compat.v1 import Session, placeholder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4116344c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#tf.config.optimizer.set_jit(True)\n",
    "\n",
    "notebooks_dir = os.path.abspath('')\n",
    "proj_dir = os.path.dirname(notebooks_dir)\n",
    "raw_data_dir = os.path.join(proj_dir, 'raw_data')\n",
    "src_dir = os.path.join(proj_dir, 'src')\n",
    "\n",
    "# Add src_dir to the system path to import helper file\n",
    "sys.path.insert(1, src_dir)\n",
    "#import cutpaste_helper\n",
    "#importlib.reload(cutpaste_helper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "873c6ff7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def makeWindows(image_dict,num_windows, width, height):\n",
    "    '''\n",
    "    Parameters:\n",
    "    image_dict: dictionary containing arrays that represent images\n",
    "    num_windows: the number of windows wanted\n",
    "    width: the width of the window\n",
    "    height: the height of the window\n",
    "    '''\n",
    "    #Grab windows from the full images from train images\n",
    "    window_images = []\n",
    "    for key in image_dict:\n",
    "    #The 100 windows per image in a list\n",
    "        for i in range(0, num_windows):\n",
    "            #Get the width and height of an image\n",
    "            dimensions = image_dict[key].shape\n",
    "            image_w = dimensions[1]\n",
    "            image_h = dimensions[0]\n",
    "            #Random coordinates\n",
    "            random_x_coord = random.randint(0, image_w - width)\n",
    "            random_y_coord = random.randint(0, image_h-height)\n",
    "            #Takes window out of a random part of the images at the random coordinates\n",
    "            window = image_dict[key][random_y_coord:random_y_coord + window_y, random_x_coord:random_x_coord + window_x]\n",
    "            window_images.append(window)\n",
    "    window_images = np.array(window_images)\n",
    "    return window_images\n",
    "\n",
    "def makeWhiteSquares(window_list):\n",
    "    #Create test window images dict with white square defects\n",
    "    defect_window_list = np.copy(window_list)\n",
    "#Fill defect train window images\n",
    "    for image in defect_window_list:\n",
    "        #Random sized white square (2D array full of ones)\n",
    "        sq_random_x = random.randint(5,25)\n",
    "        sq_random_y = random.randint(5,25)\n",
    "        white_square = np.ones((sq_random_y,sq_random_x))\n",
    "        #Random coordinates for the square\n",
    "        random_x_coord = random.randint(0,window_x-sq_random_x)\n",
    "        random_y_coord = random.randint(0,window_y-sq_random_y)\n",
    "        #Replace the coordinates with white square\n",
    "        image[random_y_coord:random_y_coord + sq_random_y, random_x_coord: random_x_coord + sq_random_x,0] = white_square\n",
    "    return defect_window_list\n",
    "\n",
    "def copyPaste(image):\n",
    "    copied_image = np.copy(image)\n",
    "    #Random sized copy-pasted area (2D array)\n",
    "    sq_random_x = random.randint(5,25)\n",
    "    sq_random_y = random.randint(5,25)\n",
    "    #Random coordinates for the square\n",
    "    random_x_coord = random.randint(0,image.shape[1]-sq_random_x)\n",
    "    random_y_coord = random.randint(0,image.shape[0]-sq_random_y)\n",
    "    #Copy the area\n",
    "    copyArea = image[random_y_coord:random_y_coord + sq_random_y, random_x_coord: random_x_coord + sq_random_x,0]\n",
    "    #Paste coordinates\n",
    "    random_x_coord = random.randint(0,window_x-sq_random_x)\n",
    "    random_y_coord = random.randint(0,window_y-sq_random_y)\n",
    "    #Paste the area\n",
    "    copied_image[random_y_coord:random_y_coord + sq_random_y, random_x_coord: random_x_coord + sq_random_x,0] = copyArea\n",
    "    return copied_image\n",
    "\n",
    "def createLabels(image_list, defect_status):\n",
    "    #Create labels for the images\n",
    "    labels_list = []\n",
    "    for image in image_list:\n",
    "        if defect_status:\n",
    "            labels_list.append(1)\n",
    "        else:\n",
    "            labels_list.append(0)\n",
    "    labels_list = np.array(labels_list)\n",
    "    return labels_list\n",
    "        \n",
    "def shuffleTwoArrays(image_list, label_list):\n",
    "    #Shuffles the image and label arrays in the same way\n",
    "    randomize = np.arange(len(label_list))\n",
    "    np.random.shuffle(randomize)\n",
    "    image_list = image_list[randomize]\n",
    "    label_list = label_list[randomize]\n",
    "    return (image_list, label_list)\n",
    "\n",
    "def imageGenerator(normal_image_list, num_normal, num_defects):\n",
    "    #A generator that generates images\n",
    "    while True:\n",
    "        generated_images = []\n",
    "        generated_labels = []\n",
    "        for i in range(num_normal):\n",
    "            random_index = random.randint(0,len(normal_image_list)-1)\n",
    "            generated_images.append(normal_image_list[random_index])\n",
    "            generated_labels.append(0)\n",
    "        for i in range(num_defects):\n",
    "            random_index = random.randint(0,len(normal_image_list)-1)\n",
    "            generated_images.append(copyPaste(normal_image_list[random_index]))\n",
    "            generated_labels.append(1)\n",
    "        generated_images = np.array(generated_images)\n",
    "        generated_labels = np.array(generated_labels)\n",
    "        generated_images, generated_labels = shuffleTwoArrays(generated_images, generated_labels)\n",
    "        n = generated_images.shape[0]\n",
    "        yield generated_images, generated_labels.reshape(n, 1)\n",
    "\n",
    "def valGeneratorImages(test_x, test_y,num_desired):\n",
    "    while True:\n",
    "        generated_images = []\n",
    "        generated_labels = []\n",
    "        for i in range(num_desired):\n",
    "            random_index = random.randint(0,len(test_x)-1)\n",
    "            generated_images.append(test_x[random_index])\n",
    "            generated_labels.append(test_y[random_index])\n",
    "        yield generated_images, generated_labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "dd588d36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dictionaries with TEM images\n",
    "f_name = os.path.join(raw_data_dir, 'test_full_arrays')\n",
    "#Dict with test image arrays (each key has a value of an array of numbers between 0 and 1)\n",
    "test_full_arrays = pickle.load(open(f_name, \"rb\"))\n",
    "f_name = os.path.join(raw_data_dir, 'train_full_arrays')\n",
    "#Dict with train image arrays (each key has a value of an array of numbers between 0 and 1)\n",
    "train_full_arrays = pickle.load(open(f_name, \"rb\"))\n",
    "\n",
    "window_x = 118\n",
    "window_y = 84\n",
    "num_windows = 100\n",
    "\n",
    "#Make testing window images and labels\n",
    "test_window_images = makeWindows(test_full_arrays, num_windows, window_x, window_y)\n",
    "test_window_labels = createLabels(test_window_images, False)\n",
    "\n",
    "#Make training window images and labels\n",
    "train_window_images = makeWindows(train_full_arrays, num_windows ,window_x, window_y)\n",
    "train_window_labels = createLabels(train_window_images, False)\n",
    "\n",
    "train_gen = imageGenerator(train_window_images,32,32)\n",
    "val_gen = imageGenerator(test_window_images,512,512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "17157da5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def identity_block(X, f, filters, stage, block):\n",
    "    # defining name basis\n",
    "    conv_name_base = 'iden_res' + str(stage) + block + '_branch'\n",
    "    bn_name_base = 'iden_bn' + str(stage) + block + '_branch'\n",
    "\n",
    "    # Retrieve Filters\n",
    "    F1, F2, F3 = filters\n",
    "\n",
    "    # Save the input value. We'll need this later to add back to the main path. \n",
    "    X_shortcut = X\n",
    "\n",
    "    # First component of main path\n",
    "    X = Conv2D(filters = F1, kernel_size = (1, 1), strides = (1,1), padding = 'valid', name = conv_name_base + '2a', kernel_initializer = glorot_uniform(seed=0))(X)\n",
    "    X = BatchNormalization(axis = 3, name = bn_name_base + '2a')(X)\n",
    "    X = Activation('relu')(X)\n",
    "\n",
    "    # Second component of main path\n",
    "    X = Conv2D(filters = F2, kernel_size = (f, f), strides = (1,1), padding = 'same', name = conv_name_base + '2b', kernel_initializer = glorot_uniform(seed=0))(X)\n",
    "    X = BatchNormalization(axis = 3, name = bn_name_base + '2b')(X)\n",
    "    X = Activation('relu')(X)\n",
    "\n",
    "    # Third component of main path\n",
    "    X = Conv2D(filters = F3, kernel_size = (1, 1), strides = (1,1), padding = 'valid', name = conv_name_base + '2c', kernel_initializer = glorot_uniform(seed=0))(X)\n",
    "    X = BatchNormalization(axis = 3, name = bn_name_base + '2c')(X)\n",
    "\n",
    "    # Final step: Add shortcut value to main path, and pass it through a RELU activation\n",
    "    X = Add()([X, X_shortcut])\n",
    "    X = Activation('relu')(X)\n",
    "\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "13f51401",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/philip/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/resource_variable_ops.py:1666: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "out =  [1.1696018  0.26200402 0.82968    1.1097323  0.         0.        ]\n"
     ]
    }
   ],
   "source": [
    "ops.reset_default_graph()\n",
    "with tf.compat.v1.Session() as test:\n",
    "    A_prev = tf.compat.v1.placeholder(\"float\", [3, 4, 4, 6])\n",
    "    X = np.random.randn(3, 4, 4, 6)\n",
    "    A = identity_block(A_prev, f = 2, filters = [2, 4, 6], stage = 1, block = 'a')\n",
    "    test.run(tf.compat.v1.global_variables_initializer())\n",
    "    out = test.run([A], feed_dict={A_prev: X, K.learning_phase(): 0})\n",
    "    print(\"out = \", out[0][1][1][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d8f4dcc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convolutional_block(X, f, filters, stage, block, s = 2):\n",
    "    # defining name basis\n",
    "    conv_name_base = 'conv_res' + str(stage) + block + '_branch'\n",
    "    bn_name_base = 'conv_bn' + str(stage) + block + '_branch'\n",
    "    \n",
    "    # Retrieve Filters\n",
    "    F1, F2, F3 = filters\n",
    "    \n",
    "    # Save the input value\n",
    "    X_shortcut = X\n",
    "\n",
    "\n",
    "    ##### MAIN PATH #####\n",
    "    # First component of main path \n",
    "    X = Conv2D(F1, (1, 1), strides = (s,s), name = conv_name_base + '2a', kernel_initializer = glorot_uniform(seed=0))(X)\n",
    "    X = BatchNormalization(axis = 3, name = bn_name_base + '2a')(X)\n",
    "    X = Activation('relu')(X)\n",
    "\n",
    "    # Second component of main path\n",
    "    X = Conv2D(filters=F2, kernel_size=(f, f), strides=(1, 1), padding='same', name=conv_name_base + '2b', kernel_initializer=glorot_uniform(seed=0))(X)\n",
    "    X = BatchNormalization(axis=3, name=bn_name_base + '2b')(X)\n",
    "    X = Activation('relu')(X)\n",
    "\n",
    "    # Third component of main path\n",
    "    X = Conv2D(filters=F3, kernel_size=(1, 1), strides=(1, 1), padding='valid', name=conv_name_base + '2c', kernel_initializer=glorot_uniform(seed=0))(X)\n",
    "    X = BatchNormalization(axis=3, name=bn_name_base + '2c')(X)\n",
    "\n",
    "    \n",
    "    ##### SHORTCUT PATH ####\n",
    "    X_shortcut = Conv2D(F3, (1, 1), strides = (s,s), name = conv_name_base + '1', kernel_initializer = glorot_uniform(seed=0))(X_shortcut)\n",
    "    X_shortcut = BatchNormalization(axis = 3, name = bn_name_base + '1')(X_shortcut)\n",
    "\n",
    "    # Final step: Add shortcut value to main path, and pass it through a RELU activation\n",
    "    X = Add()([X, X_shortcut])\n",
    "    X = Activation('relu')(X)\n",
    "    \n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8e9928f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "out =  [0.54295856 1.5694413  0.8235841  0.         0.62779236 1.0388422 ]\n"
     ]
    }
   ],
   "source": [
    "ops.reset_default_graph()\n",
    "with tf.compat.v1.Session() as test:\n",
    "    A_prev = tf.compat.v1.placeholder(\"float\", [3, 4, 4, 6])\n",
    "    X = np.random.randn(3, 4, 4, 6)\n",
    "    A = convolutional_block(A_prev, f = 2, filters = [2, 4, 6], stage = 1, block = 'a')\n",
    "    test.run(tf.compat.v1.global_variables_initializer())\n",
    "    out = test.run([A], feed_dict={A_prev: X, K.learning_phase(): 0})\n",
    "    print(\"out = \", out[0][1][1][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e875727a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ResNet50(input_shape = (84, 118, 1), classes = 1):   \n",
    "    # Define the input as a tensor with shape input_shape\n",
    "    X_input = Input(input_shape)\n",
    "\n",
    "    # Zero-Padding\n",
    "    X = ZeroPadding2D((3, 3))(X_input)\n",
    "    \n",
    "    # Stage 1\n",
    "    X = Conv2D(64, (7, 7), strides = (2, 2), name = 'conv1', kernel_initializer = glorot_uniform(seed=0))(X)\n",
    "    X = BatchNormalization(axis = 3, name = 'bn_conv1')(X)\n",
    "    X = Activation('relu')(X)\n",
    "    X = MaxPooling2D((3, 3), strides=(2, 2))(X)\n",
    "\n",
    "    # Stage 2\n",
    "    X = convolutional_block(X, f = 3, filters = [64, 64, 256], stage = 2, block='a', s = 1)\n",
    "    X = identity_block(X, 3, [64, 64, 256], stage=2, block='b')\n",
    "    X = identity_block(X, 3, [64, 64, 256], stage=2, block='c')\n",
    "\n",
    "    # Stage 3\n",
    "    X = convolutional_block(X, f = 3, filters = [128, 128, 512], stage = 3, block='a', s = 2)\n",
    "    X = identity_block(X, 3, [128, 128, 512], stage=3, block='b')\n",
    "    X = identity_block(X, 3, [128, 128, 512], stage=3, block='c')\n",
    "    X = identity_block(X, 3, [128, 128, 512], stage=3, block='d')\n",
    "\n",
    "    # Stage 4\n",
    "    X = convolutional_block(X, f = 3, filters = [256, 256, 1024], stage = 4, block='a', s = 2)\n",
    "    X = identity_block(X, 3, [256, 256, 1024], stage=4, block='b')\n",
    "    X = identity_block(X, 3, [256, 256, 1024], stage=4, block='c')\n",
    "    X = identity_block(X, 3, [256, 256, 1024], stage=4, block='d')\n",
    "    X = identity_block(X, 3, [256, 256, 1024], stage=4, block='e')\n",
    "    X = identity_block(X, 3, [256, 256, 1024], stage=4, block='f')\n",
    "\n",
    "    # Stage 5\n",
    "    X = convolutional_block(X, f = 3, filters = [512, 512, 2048], stage = 5, block='a', s = 2)\n",
    "    X = identity_block(X, 3, [512, 512, 2048], stage=5, block='b')\n",
    "    X = identity_block(X, 3, [512, 512, 2048], stage=5, block='c')\n",
    "\n",
    "    # AVGPOOL.\n",
    "    X = AveragePooling2D((2, 2), name='avg_pool')(X)\n",
    "\n",
    "    # output layer\n",
    "    X = Flatten()(X)\n",
    "    X = Dense(classes, activation='sigmoid', name='fc' + str(classes), kernel_initializer = glorot_uniform(seed=0))(X)\n",
    "    \n",
    "    # Create model\n",
    "    model = Model(inputs = X_input, outputs = X, name='ResNet50')\n",
    "\n",
    "    return model\n",
    "\n",
    "def myResNet(input_shape = (84, 118, 1), classes = 1):   \n",
    "    # Define the input as a tensor with shape input_shape\n",
    "    X_input = Input(input_shape)\n",
    "\n",
    "    # Zero-Padding\n",
    "    X = ZeroPadding2D((3, 3))(X_input)\n",
    "    \n",
    "    # Stage 1\n",
    "    X = Conv2D(64, (7, 7), strides = (2, 2), name = 'conv1', kernel_initializer = glorot_uniform(seed=0))(X)\n",
    "    X = BatchNormalization(axis = 3, name = 'bn_conv1')(X)\n",
    "    X = Activation('relu')(X)\n",
    "    X = MaxPooling2D((3, 3), strides=(2, 2))(X)\n",
    "\n",
    "    # Stage 2\n",
    "    X = convolutional_block(X, f = 3, filters = [64, 64, 256], stage = 2, block='a', s = 1)\n",
    "    X = identity_block(X, 3, [64, 64, 256], stage=2, block='b')\n",
    "    X = identity_block(X, 3, [64, 64, 256], stage=2, block='c')\n",
    "\n",
    "#     # Stage 3\n",
    "#     X = convolutional_block(X, f = 3, filters = [128, 128, 512], stage = 3, block='a', s = 2)\n",
    "#     X = identity_block(X, 3, [128, 128, 512], stage=3, block='b')\n",
    "#     X = identity_block(X, 3, [128, 128, 512], stage=3, block='c')\n",
    "#     X = identity_block(X, 3, [128, 128, 512], stage=3, block='d')\n",
    "\n",
    "#     # Stage 4\n",
    "#     X = convolutional_block(X, f = 3, filters = [256, 256, 1024], stage = 4, block='a', s = 2)\n",
    "#     X = identity_block(X, 3, [256, 256, 1024], stage=4, block='b')\n",
    "#     X = identity_block(X, 3, [256, 256, 1024], stage=4, block='c')\n",
    "#     X = identity_block(X, 3, [256, 256, 1024], stage=4, block='d')\n",
    "#     X = identity_block(X, 3, [256, 256, 1024], stage=4, block='e')\n",
    "#     X = identity_block(X, 3, [256, 256, 1024], stage=4, block='f')\n",
    "\n",
    "#     # Stage 5\n",
    "#     X = convolutional_block(X, f = 3, filters = [512, 512, 2048], stage = 5, block='a', s = 2)\n",
    "#     X = identity_block(X, 3, [512, 512, 2048], stage=5, block='b')\n",
    "#     X = identity_block(X, 3, [512, 512, 2048], stage=5, block='c')\n",
    "\n",
    "    # AVGPOOL.\n",
    "    X = AveragePooling2D((2, 2), name='avg_pool')(X)\n",
    "\n",
    "    # output layer\n",
    "    X = Flatten()(X)\n",
    "    X = Dense(classes, activation='sigmoid', name='fc' + str(classes), kernel_initializer = glorot_uniform(seed=0))(X)\n",
    "    \n",
    "    # Create model\n",
    "    model = Model(inputs = X_input, outputs = X, name='ResNet50')\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "30a39022",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"ResNet50\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_5 (InputLayer)            [(None, 84, 118, 1)] 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_4 (ZeroPadding2D (None, 90, 124, 1)   0           input_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1 (Conv2D)                  (None, 42, 59, 64)   3200        zero_padding2d_4[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "bn_conv1 (BatchNormalization)   (None, 42, 59, 64)   256         conv1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_82 (Activation)      (None, 42, 59, 64)   0           bn_conv1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2D)  (None, 20, 29, 64)   0           activation_82[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv_res2a_branch2a (Conv2D)    (None, 20, 29, 64)   4160        max_pooling2d_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv_bn2a_branch2a (BatchNormal (None, 20, 29, 64)   256         conv_res2a_branch2a[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "activation_83 (Activation)      (None, 20, 29, 64)   0           conv_bn2a_branch2a[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv_res2a_branch2b (Conv2D)    (None, 20, 29, 64)   36928       activation_83[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv_bn2a_branch2b (BatchNormal (None, 20, 29, 64)   256         conv_res2a_branch2b[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "activation_84 (Activation)      (None, 20, 29, 64)   0           conv_bn2a_branch2b[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv_res2a_branch2c (Conv2D)    (None, 20, 29, 256)  16640       activation_84[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv_res2a_branch1 (Conv2D)     (None, 20, 29, 256)  16640       max_pooling2d_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv_bn2a_branch2c (BatchNormal (None, 20, 29, 256)  1024        conv_res2a_branch2c[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv_bn2a_branch1 (BatchNormali (None, 20, 29, 256)  1024        conv_res2a_branch1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "add_26 (Add)                    (None, 20, 29, 256)  0           conv_bn2a_branch2c[0][0]         \n",
      "                                                                 conv_bn2a_branch1[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "activation_85 (Activation)      (None, 20, 29, 256)  0           add_26[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "iden_res2b_branch2a (Conv2D)    (None, 20, 29, 64)   16448       activation_85[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "iden_bn2b_branch2a (BatchNormal (None, 20, 29, 64)   256         iden_res2b_branch2a[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "activation_86 (Activation)      (None, 20, 29, 64)   0           iden_bn2b_branch2a[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "iden_res2b_branch2b (Conv2D)    (None, 20, 29, 64)   36928       activation_86[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "iden_bn2b_branch2b (BatchNormal (None, 20, 29, 64)   256         iden_res2b_branch2b[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "activation_87 (Activation)      (None, 20, 29, 64)   0           iden_bn2b_branch2b[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "iden_res2b_branch2c (Conv2D)    (None, 20, 29, 256)  16640       activation_87[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "iden_bn2b_branch2c (BatchNormal (None, 20, 29, 256)  1024        iden_res2b_branch2c[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "add_27 (Add)                    (None, 20, 29, 256)  0           iden_bn2b_branch2c[0][0]         \n",
      "                                                                 activation_85[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_88 (Activation)      (None, 20, 29, 256)  0           add_27[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "iden_res2c_branch2a (Conv2D)    (None, 20, 29, 64)   16448       activation_88[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "iden_bn2c_branch2a (BatchNormal (None, 20, 29, 64)   256         iden_res2c_branch2a[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "activation_89 (Activation)      (None, 20, 29, 64)   0           iden_bn2c_branch2a[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "iden_res2c_branch2b (Conv2D)    (None, 20, 29, 64)   36928       activation_89[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "iden_bn2c_branch2b (BatchNormal (None, 20, 29, 64)   256         iden_res2c_branch2b[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "activation_90 (Activation)      (None, 20, 29, 64)   0           iden_bn2c_branch2b[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "iden_res2c_branch2c (Conv2D)    (None, 20, 29, 256)  16640       activation_90[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "iden_bn2c_branch2c (BatchNormal (None, 20, 29, 256)  1024        iden_res2c_branch2c[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "add_28 (Add)                    (None, 20, 29, 256)  0           iden_bn2c_branch2c[0][0]         \n",
      "                                                                 activation_88[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_91 (Activation)      (None, 20, 29, 256)  0           add_28[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "avg_pool (AveragePooling2D)     (None, 10, 14, 256)  0           activation_91[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "flatten_4 (Flatten)             (None, 35840)        0           avg_pool[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "fc1 (Dense)                     (None, 1)            35841       flatten_4[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 259,329\n",
      "Trainable params: 256,385\n",
      "Non-trainable params: 2,944\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# model = ResNet50(input_shape = (window_y, window_x, 1), classes = 1)\n",
    "model = myResNet(input_shape = (window_y, window_x, 1), classes = 1)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d818f0bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "44eb56b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1024, 1)\n"
     ]
    }
   ],
   "source": [
    "val_x, val_y = next(val_gen)\n",
    "print(val_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "664112d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "175/175 [==============================] - 144s 822ms/step - loss: 0.4952 - accuracy: 0.7280 - val_loss: 379.6263 - val_accuracy: 0.5000\n",
      "Epoch 2/20\n",
      "175/175 [==============================] - 141s 805ms/step - loss: 0.1684 - accuracy: 0.9368 - val_loss: 480.3725 - val_accuracy: 0.5000\n",
      "Epoch 3/20\n",
      "175/175 [==============================] - 142s 810ms/step - loss: 0.2636 - accuracy: 0.9032 - val_loss: 539.5153 - val_accuracy: 0.5000\n",
      "Epoch 4/20\n",
      "175/175 [==============================] - 141s 806ms/step - loss: 0.2035 - accuracy: 0.9264 - val_loss: 1.0632 - val_accuracy: 0.5566\n",
      "Epoch 5/20\n",
      "175/175 [==============================] - 148s 844ms/step - loss: 0.0835 - accuracy: 0.9725 - val_loss: 3.5824 - val_accuracy: 0.8242\n",
      "Epoch 6/20\n",
      "175/175 [==============================] - 143s 820ms/step - loss: 0.0649 - accuracy: 0.9807 - val_loss: 0.1968 - val_accuracy: 0.9326\n",
      "Epoch 7/20\n",
      "175/175 [==============================] - 143s 815ms/step - loss: 0.0442 - accuracy: 0.9871 - val_loss: 443.7618 - val_accuracy: 0.5000\n",
      "Epoch 8/20\n",
      "175/175 [==============================] - 138s 786ms/step - loss: 0.0646 - accuracy: 0.9821 - val_loss: 73.1109 - val_accuracy: 0.5361\n",
      "Epoch 9/20\n",
      "175/175 [==============================] - 138s 788ms/step - loss: 0.0428 - accuracy: 0.9894 - val_loss: 11.7341 - val_accuracy: 0.6094\n",
      "Epoch 10/20\n",
      "175/175 [==============================] - 138s 791ms/step - loss: 0.0757 - accuracy: 0.9785 - val_loss: 0.7838 - val_accuracy: 0.8311\n",
      "Epoch 11/20\n",
      "175/175 [==============================] - 138s 790ms/step - loss: 0.0349 - accuracy: 0.9913 - val_loss: 0.2310 - val_accuracy: 0.9502\n",
      "Epoch 12/20\n",
      "175/175 [==============================] - 136s 779ms/step - loss: 0.0597 - accuracy: 0.9831 - val_loss: 2538.3838 - val_accuracy: 0.5000\n",
      "Epoch 13/20\n",
      "175/175 [==============================] - 136s 776ms/step - loss: 0.0860 - accuracy: 0.9740 - val_loss: 0.2415 - val_accuracy: 0.9238\n",
      "Epoch 14/20\n",
      "175/175 [==============================] - 137s 783ms/step - loss: 0.0609 - accuracy: 0.9841 - val_loss: 14.1801 - val_accuracy: 0.6025\n",
      "Epoch 15/20\n",
      "175/175 [==============================] - 137s 781ms/step - loss: 0.0486 - accuracy: 0.9879 - val_loss: 1.3235 - val_accuracy: 0.8711\n",
      "Epoch 16/20\n",
      "175/175 [==============================] - 137s 782ms/step - loss: 0.0489 - accuracy: 0.9883 - val_loss: 0.0942 - val_accuracy: 0.9746\n",
      "Epoch 17/20\n",
      "175/175 [==============================] - 137s 785ms/step - loss: 0.0336 - accuracy: 0.9926 - val_loss: 0.1534 - val_accuracy: 0.9609\n",
      "Epoch 18/20\n",
      "175/175 [==============================] - 137s 783ms/step - loss: 0.0293 - accuracy: 0.9932 - val_loss: 0.4324 - val_accuracy: 0.9014\n",
      "Epoch 19/20\n",
      "175/175 [==============================] - 136s 776ms/step - loss: 0.0284 - accuracy: 0.9940 - val_loss: 0.0470 - val_accuracy: 0.9893\n",
      "Epoch 20/20\n",
      "175/175 [==============================] - 136s 779ms/step - loss: 0.1565 - accuracy: 0.9619 - val_loss: 0.1589 - val_accuracy: 0.9434\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "  train_gen,\n",
    "  validation_data = (val_x, val_y),\n",
    "  validation_batch_size = int(len(val_x)*.5),\n",
    "  epochs = 20,\n",
    "  steps_per_epoch=len(train_window_images)//64,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "a39b84fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "175/175 [==============================] - 204s 1s/step - loss: 0.0156 - accuracy: 0.9969 - val_loss: 0.0594 - val_accuracy: 0.9844\n",
      "Epoch 2/20\n",
      "175/175 [==============================] - 204s 1s/step - loss: 0.0201 - accuracy: 0.9953 - val_loss: 0.0898 - val_accuracy: 0.9814\n",
      "Epoch 3/20\n",
      "175/175 [==============================] - 171s 978ms/step - loss: 0.0183 - accuracy: 0.9966 - val_loss: 0.0806 - val_accuracy: 0.9844\n",
      "Epoch 4/20\n",
      "175/175 [==============================] - 172s 980ms/step - loss: 0.0460 - accuracy: 0.9900 - val_loss: 0.2361 - val_accuracy: 0.9473\n",
      "Epoch 5/20\n",
      "175/175 [==============================] - 169s 967ms/step - loss: 0.0293 - accuracy: 0.9935 - val_loss: 0.0340 - val_accuracy: 0.9922\n",
      "Epoch 6/20\n",
      "175/175 [==============================] - 171s 977ms/step - loss: 0.0220 - accuracy: 0.9952 - val_loss: 0.0641 - val_accuracy: 0.9854\n",
      "Epoch 7/20\n",
      "175/175 [==============================] - 172s 983ms/step - loss: 0.0578 - accuracy: 0.9876 - val_loss: 1.1094 - val_accuracy: 0.8428\n",
      "Epoch 8/20\n",
      "175/175 [==============================] - 171s 977ms/step - loss: 0.0303 - accuracy: 0.9934 - val_loss: 0.0594 - val_accuracy: 0.9863\n",
      "Epoch 9/20\n",
      "175/175 [==============================] - 171s 979ms/step - loss: 0.0208 - accuracy: 0.9961 - val_loss: 0.0370 - val_accuracy: 0.9902\n",
      "Epoch 10/20\n",
      "175/175 [==============================] - 170s 970ms/step - loss: 0.0182 - accuracy: 0.9959 - val_loss: 0.0166 - val_accuracy: 0.9971\n",
      "Epoch 11/20\n",
      "175/175 [==============================] - 170s 970ms/step - loss: 0.0097 - accuracy: 0.9981 - val_loss: 0.0441 - val_accuracy: 0.9912\n",
      "Epoch 12/20\n",
      "175/175 [==============================] - 170s 970ms/step - loss: 0.0203 - accuracy: 0.9962 - val_loss: 0.0221 - val_accuracy: 0.9951\n",
      "Epoch 13/20\n",
      "175/175 [==============================] - 170s 974ms/step - loss: 0.0142 - accuracy: 0.9972 - val_loss: 0.0188 - val_accuracy: 0.9971\n",
      "Epoch 14/20\n",
      "175/175 [==============================] - 169s 967ms/step - loss: 0.0183 - accuracy: 0.9965 - val_loss: 0.0341 - val_accuracy: 0.9883\n",
      "Epoch 15/20\n",
      "175/175 [==============================] - 172s 982ms/step - loss: 0.0221 - accuracy: 0.9958 - val_loss: 0.0317 - val_accuracy: 0.9922\n",
      "Epoch 16/20\n",
      "175/175 [==============================] - 172s 980ms/step - loss: 0.0156 - accuracy: 0.9972 - val_loss: 0.0208 - val_accuracy: 0.9951\n",
      "Epoch 17/20\n",
      "175/175 [==============================] - 171s 977ms/step - loss: 0.0148 - accuracy: 0.9975 - val_loss: 0.0363 - val_accuracy: 0.9922\n",
      "Epoch 18/20\n",
      "175/175 [==============================] - 171s 976ms/step - loss: 0.0230 - accuracy: 0.9953 - val_loss: 0.5181 - val_accuracy: 0.9619\n",
      "Epoch 19/20\n",
      "175/175 [==============================] - 169s 967ms/step - loss: 0.0171 - accuracy: 0.9962 - val_loss: 0.0373 - val_accuracy: 0.9922\n",
      "Epoch 20/20\n",
      "175/175 [==============================] - 171s 979ms/step - loss: 0.0358 - accuracy: 0.9937 - val_loss: 0.0610 - val_accuracy: 0.9854\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "  train_gen,\n",
    "  validation_data = (val_x, val_y),\n",
    "  validation_batch_size = int(len(val_x)),\n",
    "  epochs = 20,\n",
    "  steps_per_epoch=len(train_window_images)//64,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "620b4ee8-ebe0-4615-9a54-7885ac36c559",
   "metadata": {},
   "outputs": [],
   "source": [
    "#currently at 80 epochs"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
