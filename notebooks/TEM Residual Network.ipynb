{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "eafa15d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import importlib\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import random\n",
    "import numpy as np\n",
    "from keras import layers\n",
    "from tensorflow.keras.models import Sequential\n",
    "from keras.layers import Input, Add, Dense, Activation, ZeroPadding2D, BatchNormalization, Flatten, Conv2D, AveragePooling2D, MaxPooling2D\n",
    "from keras.models import Model, load_model\n",
    "from keras.initializers import glorot_uniform\n",
    "from keras.utils import plot_model\n",
    "from IPython.display import SVG\n",
    "from keras.utils.vis_utils import model_to_dot\n",
    "import keras.backend as K\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.framework import ops\n",
    "from tensorflow.compat.v1 import Session, placeholder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4116344c",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.config.optimizer.set_jit(True)\n",
    "\n",
    "notebooks_dir = os.path.abspath('')\n",
    "proj_dir = os.path.dirname(notebooks_dir)\n",
    "raw_data_dir = os.path.join(proj_dir, 'raw_data')\n",
    "src_dir = os.path.join(proj_dir, 'src')\n",
    "\n",
    "# Add src_dir to the system path to import helper file\n",
    "sys.path.insert(1, src_dir)\n",
    "#import cutpaste_helper\n",
    "#importlib.reload(cutpaste_helper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "ffb3d226",
   "metadata": {},
   "outputs": [],
   "source": [
    "def makeWindows(image_dict,num_windows, width, height):\n",
    "    '''\n",
    "    Parameters:\n",
    "    image_dict: dictionary containing arrays that represent images\n",
    "    num_windows: the number of windows wanted\n",
    "    width: the width of the window\n",
    "    height: the height of the window\n",
    "    '''\n",
    "    #Grab windows from the full images from train images\n",
    "    window_images = []\n",
    "    for key in image_dict:\n",
    "    #The 100 windows per image in a list\n",
    "        for i in range(0, num_windows):\n",
    "            #Get the width and height of an image\n",
    "            dimensions = image_dict[key].shape\n",
    "            image_w = dimensions[1]\n",
    "            image_h = dimensions[0]\n",
    "            #Random coordinates\n",
    "            random_x_coord = random.randint(0, image_w - width)\n",
    "            random_y_coord = random.randint(0, image_h-height)\n",
    "            #Takes window out of a random part of the images at the random coordinates\n",
    "            window = image_dict[key][random_y_coord:random_y_coord + window_y, random_x_coord:random_x_coord + window_x]\n",
    "            window_images.append(window)\n",
    "    window_images = np.array(window_images)\n",
    "    return window_images\n",
    "\n",
    "def makeWhiteSquares(window_list):\n",
    "    #Create test window images dict with white square defects\n",
    "    defect_window_list = np.copy(window_list)\n",
    "#Fill defect train window images\n",
    "    for image in defect_window_list:\n",
    "        #Random sized white square (2D array full of ones)\n",
    "        sq_random_x = random.randint(5,25)\n",
    "        sq_random_y = random.randint(5,25)\n",
    "        white_square = np.ones((sq_random_y,sq_random_x))\n",
    "        #Random coordinates for the square\n",
    "        random_x_coord = random.randint(0,window_x-sq_random_x)\n",
    "        random_y_coord = random.randint(0,window_y-sq_random_y)\n",
    "        #Replace the coordinates with white square\n",
    "        image[random_y_coord:random_y_coord + sq_random_y, random_x_coord: random_x_coord + sq_random_x,0] = white_square\n",
    "    return defect_window_list\n",
    "\n",
    "def copyPaste(image):\n",
    "    copied_image = np.copy(image)\n",
    "    #Random sized copy-pasted area (2D array)\n",
    "    sq_random_x = random.randint(5,25)\n",
    "    sq_random_y = random.randint(5,25)\n",
    "    #Random coordinates for the square\n",
    "    random_x_coord = random.randint(0,image.shape[1]-sq_random_x)\n",
    "    random_y_coord = random.randint(0,image.shape[0]-sq_random_y)\n",
    "    #Copy the area\n",
    "    copyArea = image[random_y_coord:random_y_coord + sq_random_y, random_x_coord: random_x_coord + sq_random_x,0]\n",
    "    #Paste coordinates\n",
    "    random_x_coord = random.randint(0,window_x-sq_random_x)\n",
    "    random_y_coord = random.randint(0,window_y-sq_random_y)\n",
    "    #Paste the area\n",
    "    copied_image[random_y_coord:random_y_coord + sq_random_y, random_x_coord: random_x_coord + sq_random_x,0] = copyArea\n",
    "    return copied_image\n",
    "\n",
    "def createLabels(image_list, defect_status):\n",
    "    #Create labels for the images\n",
    "    labels_list = []\n",
    "    for image in image_list:\n",
    "        if defect_status:\n",
    "            labels_list.append(1)\n",
    "        else:\n",
    "            labels_list.append(0)\n",
    "    labels_list = np.array(labels_list)\n",
    "    return labels_list\n",
    "        \n",
    "def shuffleTwoArrays(image_list, label_list):\n",
    "    #Shuffles the image and label arrays in the same way\n",
    "    randomize = np.arange(len(label_list))\n",
    "    np.random.shuffle(randomize)\n",
    "    image_list = image_list[randomize]\n",
    "    label_list = label_list[randomize]\n",
    "    return (image_list, label_list)\n",
    "\n",
    "def imageGenerator(normal_image_list, num_normal, num_defects):\n",
    "    #A generator that generates images\n",
    "    while True:\n",
    "        generated_images = []\n",
    "        generated_labels = []\n",
    "        for i in range(num_normal):\n",
    "            random_index = random.randint(0,len(normal_image_list)-1)\n",
    "            generated_images.append(normal_image_list[random_index])\n",
    "            generated_labels.append(0)\n",
    "        for i in range(num_defects):\n",
    "            random_index = random.randint(0,len(normal_image_list)-1)\n",
    "            generated_images.append(copyPaste(normal_image_list[random_index]))\n",
    "            generated_labels.append(1)\n",
    "        generated_images = np.array(generated_images)\n",
    "        generated_labels = np.array(generated_labels)\n",
    "        generated_images, generated_labels = shuffleTwoArrays(generated_images, generated_labels)\n",
    "        n = generated_images.shape[0]\n",
    "        yield generated_images, generated_labels.reshape(n, 1)\n",
    "\n",
    "def valGeneratorImages(test_x, test_y,num_desired):\n",
    "    while True:\n",
    "        generated_images = []\n",
    "        generated_labels = []\n",
    "        for i in range(num_desired):\n",
    "            random_index = random.randint(0,len(test_x)-1)\n",
    "            generated_images.append(test_x[random_index])\n",
    "            generated_labels.append(test_y[random_index])\n",
    "        yield generated_images, generated_labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "5cc1b855",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dictionaries with TEM images\n",
    "f_name = os.path.join(raw_data_dir, 'test_full_arrays')\n",
    "#Dict with test image arrays (each key has a value of an array of numbers between 0 and 1)\n",
    "test_full_arrays = pickle.load(open(f_name, \"rb\"))\n",
    "f_name = os.path.join(raw_data_dir, 'train_full_arrays')\n",
    "#Dict with train image arrays (each key has a value of an array of numbers between 0 and 1)\n",
    "train_full_arrays = pickle.load(open(f_name, \"rb\"))\n",
    "\n",
    "window_x = 118\n",
    "window_y = 84\n",
    "num_windows = 100\n",
    "\n",
    "#Make testing window images and labels\n",
    "test_window_images = makeWindows(test_full_arrays, num_windows, window_x, window_y)\n",
    "test_window_labels = createLabels(test_window_images, False)\n",
    "\n",
    "#Make training window images and labels\n",
    "train_window_images = makeWindows(train_full_arrays, num_windows ,window_x, window_y)\n",
    "train_window_labels = createLabels(train_window_images, False)\n",
    "\n",
    "train_gen = imageGenerator(train_window_images,32,32)\n",
    "val_gen = imageGenerator(test_window_images,32,32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "b2378551",
   "metadata": {},
   "outputs": [],
   "source": [
    "def identity_block(X, f, filters, stage, block):\n",
    "    # defining name basis\n",
    "    conv_name_base = 'res' + str(stage) + block + '_branch'\n",
    "    bn_name_base = 'bn' + str(stage) + block + '_branch'\n",
    "\n",
    "    # Retrieve Filters\n",
    "    F1, F2, F3 = filters\n",
    "\n",
    "    # Save the input value. We'll need this later to add back to the main path. \n",
    "    X_shortcut = X\n",
    "\n",
    "    # First component of main path\n",
    "    X = Conv2D(filters = F1, kernel_size = (1, 1), strides = (1,1), padding = 'valid', name = conv_name_base + '2a', kernel_initializer = glorot_uniform(seed=0))(X)\n",
    "    X = BatchNormalization(axis = 3, name = bn_name_base + '2a')(X)\n",
    "    X = Activation('relu')(X)\n",
    "\n",
    "    # Second component of main path\n",
    "    X = Conv2D(filters = F2, kernel_size = (f, f), strides = (1,1), padding = 'same', name = conv_name_base + '2b', kernel_initializer = glorot_uniform(seed=0))(X)\n",
    "    X = BatchNormalization(axis = 3, name = bn_name_base + '2b')(X)\n",
    "    X = Activation('relu')(X)\n",
    "\n",
    "    # Third component of main path\n",
    "    X = Conv2D(filters = F3, kernel_size = (1, 1), strides = (1,1), padding = 'valid', name = conv_name_base + '2c', kernel_initializer = glorot_uniform(seed=0))(X)\n",
    "    X = BatchNormalization(axis = 3, name = bn_name_base + '2c')(X)\n",
    "\n",
    "    # Final step: Add shortcut value to main path, and pass it through a RELU activation\n",
    "    X = Add()([X, X_shortcut])\n",
    "    X = Activation('relu')(X)\n",
    "\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "f5a601b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "out =  [0.06488273 0.         0.13424343 0.66184264 1.7185395  0.        ]\n"
     ]
    }
   ],
   "source": [
    "ops.reset_default_graph()\n",
    "with tf.compat.v1.Session() as test:\n",
    "    A_prev = tf.compat.v1.placeholder(\"float\", [3, 4, 4, 6])\n",
    "    X = np.random.randn(3, 4, 4, 6)\n",
    "    A = identity_block(A_prev, f = 2, filters = [2, 4, 6], stage = 1, block = 'a')\n",
    "    test.run(tf.compat.v1.global_variables_initializer())\n",
    "    out = test.run([A], feed_dict={A_prev: X, K.learning_phase(): 0})\n",
    "    print(\"out = \", out[0][1][1][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "42c7f00d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convolutional_block(X, f, filters, stage, block, s = 2):\n",
    "    # defining name basis\n",
    "    conv_name_base = 'res' + str(stage) + block + '_branch'\n",
    "    bn_name_base = 'bn' + str(stage) + block + '_branch'\n",
    "    \n",
    "    # Retrieve Filters\n",
    "    F1, F2, F3 = filters\n",
    "    \n",
    "    # Save the input value\n",
    "    X_shortcut = X\n",
    "\n",
    "\n",
    "    ##### MAIN PATH #####\n",
    "    # First component of main path \n",
    "    X = Conv2D(F1, (1, 1), strides = (s,s), name = conv_name_base + '2a', kernel_initializer = glorot_uniform(seed=0))(X)\n",
    "    X = BatchNormalization(axis = 3, name = bn_name_base + '2a')(X)\n",
    "    X = Activation('relu')(X)\n",
    "\n",
    "    # Second component of main path\n",
    "    X = Conv2D(filters=F2, kernel_size=(f, f), strides=(1, 1), padding='same', name=conv_name_base + '2b', kernel_initializer=glorot_uniform(seed=0))(X)\n",
    "    X = BatchNormalization(axis=3, name=bn_name_base + '2b')(X)\n",
    "    X = Activation('relu')(X)\n",
    "\n",
    "    # Third component of main path\n",
    "    X = Conv2D(filters=F3, kernel_size=(1, 1), strides=(1, 1), padding='valid', name=conv_name_base + '2c', kernel_initializer=glorot_uniform(seed=0))(X)\n",
    "    X = BatchNormalization(axis=3, name=bn_name_base + '2c')(X)\n",
    "\n",
    "    \n",
    "    ##### SHORTCUT PATH ####\n",
    "    X_shortcut = Conv2D(F3, (1, 1), strides = (s,s), name = conv_name_base + '1', kernel_initializer = glorot_uniform(seed=0))(X_shortcut)\n",
    "    X_shortcut = BatchNormalization(axis = 3, name = bn_name_base + '1')(X_shortcut)\n",
    "\n",
    "    # Final step: Add shortcut value to main path, and pass it through a RELU activation\n",
    "    X = Add()([X, X_shortcut])\n",
    "    X = Activation('relu')(X)\n",
    "    \n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "c26efd7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "out =  [0.77141976 1.1048952  0.4297085  0.47085506 0.18298286 0.40075877]\n"
     ]
    }
   ],
   "source": [
    "ops.reset_default_graph()\n",
    "with tf.compat.v1.Session() as test:\n",
    "    A_prev = tf.compat.v1.placeholder(\"float\", [3, 4, 4, 6])\n",
    "    X = np.random.randn(3, 4, 4, 6)\n",
    "    A = convolutional_block(A_prev, f = 2, filters = [2, 4, 6], stage = 1, block = 'a')\n",
    "    test.run(tf.compat.v1.global_variables_initializer())\n",
    "    out = test.run([A], feed_dict={A_prev: X, K.learning_phase(): 0})\n",
    "    print(\"out = \", out[0][1][1][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "00a006a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ResNet50(input_shape = (84, 118, 1), classes = 1):   \n",
    "    # Define the input as a tensor with shape input_shape\n",
    "    X_input = Input(input_shape)\n",
    "\n",
    "    # Zero-Padding\n",
    "    X = ZeroPadding2D((3, 3))(X_input)\n",
    "    \n",
    "    # Stage 1\n",
    "    X = Conv2D(64, (7, 7), strides = (2, 2), name = 'conv1', kernel_initializer = glorot_uniform(seed=0))(X)\n",
    "    X = BatchNormalization(axis = 3, name = 'bn_conv1')(X)\n",
    "    X = Activation('relu')(X)\n",
    "    X = MaxPooling2D((3, 3), strides=(2, 2))(X)\n",
    "\n",
    "    # Stage 2\n",
    "    X = convolutional_block(X, f = 3, filters = [64, 64, 256], stage = 2, block='a', s = 1)\n",
    "    X = identity_block(X, 3, [64, 64, 256], stage=2, block='b')\n",
    "    X = identity_block(X, 3, [64, 64, 256], stage=2, block='c')\n",
    "\n",
    "    # Stage 3\n",
    "    X = convolutional_block(X, f = 3, filters = [128, 128, 512], stage = 3, block='a', s = 2)\n",
    "    X = identity_block(X, 3, [128, 128, 512], stage=3, block='b')\n",
    "    X = identity_block(X, 3, [128, 128, 512], stage=3, block='c')\n",
    "    X = identity_block(X, 3, [128, 128, 512], stage=3, block='d')\n",
    "\n",
    "    # Stage 4\n",
    "    X = convolutional_block(X, f = 3, filters = [256, 256, 1024], stage = 4, block='a', s = 2)\n",
    "    X = identity_block(X, 3, [256, 256, 1024], stage=4, block='b')\n",
    "    X = identity_block(X, 3, [256, 256, 1024], stage=4, block='c')\n",
    "    X = identity_block(X, 3, [256, 256, 1024], stage=4, block='d')\n",
    "    X = identity_block(X, 3, [256, 256, 1024], stage=4, block='e')\n",
    "    X = identity_block(X, 3, [256, 256, 1024], stage=4, block='f')\n",
    "\n",
    "    # Stage 5\n",
    "    X = convolutional_block(X, f = 3, filters = [512, 512, 2048], stage = 5, block='a', s = 2)\n",
    "    X = identity_block(X, 3, [512, 512, 2048], stage=5, block='b')\n",
    "    X = identity_block(X, 3, [512, 512, 2048], stage=5, block='c')\n",
    "\n",
    "    # AVGPOOL.\n",
    "    X = AveragePooling2D((2, 2), name='avg_pool')(X)\n",
    "\n",
    "    # output layer\n",
    "    X = Flatten()(X)\n",
    "    X = Dense(classes, activation='sigmoid', name='fc' + str(classes), kernel_initializer = glorot_uniform(seed=0))(X)\n",
    "    \n",
    "    # Create model\n",
    "    model = Model(inputs = X_input, outputs = X, name='ResNet50')\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "6ef54328",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ResNet50(input_shape = (window_y, window_x, 1), classes = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "87248aaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "e1d0da52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[[0.37511218]\n",
      "   [0.28696838]\n",
      "   [0.23767538]\n",
      "   ...\n",
      "   [0.6028358 ]\n",
      "   [0.58845216]\n",
      "   [0.531106  ]]\n",
      "\n",
      "  [[0.43222442]\n",
      "   [0.3758421 ]\n",
      "   [0.34482718]\n",
      "   ...\n",
      "   [0.53943855]\n",
      "   [0.5355291 ]\n",
      "   [0.5124195 ]]\n",
      "\n",
      "  [[0.4382936 ]\n",
      "   [0.4149782 ]\n",
      "   [0.4065657 ]\n",
      "   ...\n",
      "   [0.49028865]\n",
      "   [0.48640412]\n",
      "   [0.47316015]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.07009748]\n",
      "   [0.04494959]\n",
      "   [0.08002889]\n",
      "   ...\n",
      "   [0.52183086]\n",
      "   [0.46494868]\n",
      "   [0.3099079 ]]\n",
      "\n",
      "  [[0.15756322]\n",
      "   [0.08136813]\n",
      "   [0.06447369]\n",
      "   ...\n",
      "   [0.6024496 ]\n",
      "   [0.5553747 ]\n",
      "   [0.4169563 ]]\n",
      "\n",
      "  [[0.27429032]\n",
      "   [0.1772181 ]\n",
      "   [0.13197085]\n",
      "   ...\n",
      "   [0.63155246]\n",
      "   [0.60075015]\n",
      "   [0.4996116 ]]]\n",
      "\n",
      "\n",
      " [[[0.0181729 ]\n",
      "   [0.00789853]\n",
      "   [0.01147895]\n",
      "   ...\n",
      "   [0.06524457]\n",
      "   [0.07380418]\n",
      "   [0.06064562]]\n",
      "\n",
      "  [[0.04082766]\n",
      "   [0.01715062]\n",
      "   [0.01025954]\n",
      "   ...\n",
      "   [0.10505583]\n",
      "   [0.11482809]\n",
      "   [0.09874526]]\n",
      "\n",
      "  [[0.08261613]\n",
      "   [0.04498907]\n",
      "   [0.02434265]\n",
      "   ...\n",
      "   [0.16515726]\n",
      "   [0.17690834]\n",
      "   [0.15728669]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.05064219]\n",
      "   [0.03731005]\n",
      "   [0.02710303]\n",
      "   ...\n",
      "   [0.08750858]\n",
      "   [0.09463755]\n",
      "   [0.08420222]]\n",
      "\n",
      "  [[0.02296207]\n",
      "   [0.01982367]\n",
      "   [0.02105439]\n",
      "   ...\n",
      "   [0.05251978]\n",
      "   [0.05924246]\n",
      "   [0.04936374]]\n",
      "\n",
      "  [[0.01341489]\n",
      "   [0.01060731]\n",
      "   [0.01673043]\n",
      "   ...\n",
      "   [0.04824799]\n",
      "   [0.05579364]\n",
      "   [0.04467528]]]\n",
      "\n",
      "\n",
      " [[[0.3256106 ]\n",
      "   [0.3752364 ]\n",
      "   [0.45217633]\n",
      "   ...\n",
      "   [0.2860016 ]\n",
      "   [0.28342855]\n",
      "   [0.29051158]]\n",
      "\n",
      "  [[0.22521609]\n",
      "   [0.24280109]\n",
      "   [0.28629673]\n",
      "   ...\n",
      "   [0.20461793]\n",
      "   [0.20821914]\n",
      "   [0.21574405]]\n",
      "\n",
      "  [[0.1990563 ]\n",
      "   [0.19243538]\n",
      "   [0.19784883]\n",
      "   ...\n",
      "   [0.15924346]\n",
      "   [0.17842337]\n",
      "   [0.19516942]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.8282471 ]\n",
      "   [0.8708692 ]\n",
      "   [0.865044  ]\n",
      "   ...\n",
      "   [0.6432221 ]\n",
      "   [0.6722522 ]\n",
      "   [0.7190962 ]]\n",
      "\n",
      "  [[0.67305243]\n",
      "   [0.7475322 ]\n",
      "   [0.80411786]\n",
      "   ...\n",
      "   [0.526046  ]\n",
      "   [0.5389393 ]\n",
      "   [0.56960803]]\n",
      "\n",
      "  [[0.4823184 ]\n",
      "   [0.55698085]\n",
      "   [0.64451057]\n",
      "   ...\n",
      "   [0.3959218 ]\n",
      "   [0.3966153 ]\n",
      "   [0.41141635]]]\n",
      "\n",
      "\n",
      " ...\n",
      "\n",
      "\n",
      " [[[0.08058457]\n",
      "   [0.07906206]\n",
      "   [0.08124539]\n",
      "   ...\n",
      "   [0.14452703]\n",
      "   [0.12350736]\n",
      "   [0.10233545]]\n",
      "\n",
      "  [[0.11381656]\n",
      "   [0.11397851]\n",
      "   [0.11460605]\n",
      "   ...\n",
      "   [0.17215104]\n",
      "   [0.14907032]\n",
      "   [0.1277589 ]]\n",
      "\n",
      "  [[0.14640592]\n",
      "   [0.14530443]\n",
      "   [0.14647989]\n",
      "   ...\n",
      "   [0.19113365]\n",
      "   [0.17088874]\n",
      "   [0.15429427]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.03254623]\n",
      "   [0.02727872]\n",
      "   [0.02139376]\n",
      "   ...\n",
      "   [0.05869203]\n",
      "   [0.04558532]\n",
      "   [0.03730502]]\n",
      "\n",
      "  [[0.04067368]\n",
      "   [0.03243938]\n",
      "   [0.03017021]\n",
      "   ...\n",
      "   [0.08721992]\n",
      "   [0.07354502]\n",
      "   [0.06058938]]\n",
      "\n",
      "  [[0.05681093]\n",
      "   [0.05112806]\n",
      "   [0.05232292]\n",
      "   ...\n",
      "   [0.1158834 ]\n",
      "   [0.09908979]\n",
      "   [0.08169203]]]\n",
      "\n",
      "\n",
      " [[[0.27227598]\n",
      "   [0.25301284]\n",
      "   [0.22549637]\n",
      "   ...\n",
      "   [0.24340616]\n",
      "   [0.26252416]\n",
      "   [0.27481622]]\n",
      "\n",
      "  [[0.22391047]\n",
      "   [0.21138263]\n",
      "   [0.19080172]\n",
      "   ...\n",
      "   [0.20058033]\n",
      "   [0.21363221]\n",
      "   [0.22275496]]\n",
      "\n",
      "  [[0.18107192]\n",
      "   [0.17715678]\n",
      "   [0.16443759]\n",
      "   ...\n",
      "   [0.15371564]\n",
      "   [0.16252074]\n",
      "   [0.17120315]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.34882498]\n",
      "   [0.32672557]\n",
      "   [0.2957842 ]\n",
      "   ...\n",
      "   [0.30781648]\n",
      "   [0.33413547]\n",
      "   [0.3499333 ]]\n",
      "\n",
      "  [[0.343377  ]\n",
      "   [0.32099998]\n",
      "   [0.2897739 ]\n",
      "   ...\n",
      "   [0.3028861 ]\n",
      "   [0.32891867]\n",
      "   [0.34475553]]\n",
      "\n",
      "  [[0.31416476]\n",
      "   [0.29180408]\n",
      "   [0.26075795]\n",
      "   ...\n",
      "   [0.27795482]\n",
      "   [0.30170116]\n",
      "   [0.31669363]]]\n",
      "\n",
      "\n",
      " [[[0.7719657 ]\n",
      "   [0.8237306 ]\n",
      "   [0.8694699 ]\n",
      "   ...\n",
      "   [0.6699458 ]\n",
      "   [0.67789364]\n",
      "   [0.7005478 ]]\n",
      "\n",
      "  [[0.81277055]\n",
      "   [0.849369  ]\n",
      "   [0.86602765]\n",
      "   ...\n",
      "   [0.6741512 ]\n",
      "   [0.70002496]\n",
      "   [0.7367707 ]]\n",
      "\n",
      "  [[0.7988569 ]\n",
      "   [0.8158703 ]\n",
      "   [0.80447215]\n",
      "   ...\n",
      "   [0.6467373 ]\n",
      "   [0.6855854 ]\n",
      "   [0.7302191 ]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.42216137]\n",
      "   [0.46090397]\n",
      "   [0.52542037]\n",
      "   ...\n",
      "   [0.48266876]\n",
      "   [0.4371426 ]\n",
      "   [0.41238227]]\n",
      "\n",
      "  [[0.56054026]\n",
      "   [0.61277366]\n",
      "   [0.68686616]\n",
      "   ...\n",
      "   [0.5722774 ]\n",
      "   [0.541215  ]\n",
      "   [0.5291072 ]]\n",
      "\n",
      "  [[0.68880117]\n",
      "   [0.7468966 ]\n",
      "   [0.8144721 ]\n",
      "   ...\n",
      "   [0.63868624]\n",
      "   [0.6273332 ]\n",
      "   [0.63298506]]]] [[1]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [0]]\n"
     ]
    }
   ],
   "source": [
    "val_x, val_y = next(val_gen)\n",
    "print(val_x, val_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c90aa48e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "111/175 [==================>...........] - ETA: 7:18 - loss: 1.0181 - accuracy: 0.5099"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "  train_gen,\n",
    "  validation_data = (val_x, val_y),\n",
    "  validation_batch_size = int(len(val_x)*.5),\n",
    "  epochs = 100,\n",
    "  steps_per_epoch=len(train_window_images)//64,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff3548fe",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
