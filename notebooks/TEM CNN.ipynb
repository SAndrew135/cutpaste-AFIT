{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "54afb26f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import importlib\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import random\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, GaussianNoise, BatchNormalization\n",
    "from tensorflow.keras.layers import Activation, Dropout, Flatten, Dense\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "969c2987",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tf.config.optimizer.set_jit(True)\n",
    "\n",
    "notebooks_dir = os.path.abspath('')\n",
    "proj_dir = os.path.dirname(notebooks_dir)\n",
    "raw_data_dir = os.path.join(proj_dir, 'raw_data')\n",
    "src_dir = os.path.join(proj_dir, 'src')\n",
    "\n",
    "# Add src_dir to the system path to import helper file\n",
    "sys.path.insert(1, src_dir)\n",
    "#import cutpaste_helper\n",
    "#importlib.reload(cutpaste_helper)\n",
    "\n",
    "def makeWindows(image_dict,num_windows, width, height):\n",
    "    '''\n",
    "    Parameters:\n",
    "    image_dict: dictionary containing arrays that represent images\n",
    "    num_windows: the number of windows wanted\n",
    "    width: the width of the window\n",
    "    height: the height of the window\n",
    "    '''\n",
    "    #Grab windows from the full images from train images\n",
    "    window_images = []\n",
    "    for key in image_dict:\n",
    "    #The 100 windows per image in a list\n",
    "        for i in range(0, num_windows):\n",
    "            #Get the width and height of an image\n",
    "            dimensions = image_dict[key].shape\n",
    "            image_w = dimensions[1]\n",
    "            image_h = dimensions[0]\n",
    "            #Random coordinates\n",
    "            random_x_coord = random.randint(0, image_w - width)\n",
    "            random_y_coord = random.randint(0, image_h-height)\n",
    "            #Takes window out of a random part of the images at the random coordinates\n",
    "            window = image_dict[key][random_y_coord:random_y_coord + window_y, random_x_coord:random_x_coord + window_x]\n",
    "            window_images.append(window)\n",
    "    window_images = np.array(window_images)\n",
    "    return window_images\n",
    "\n",
    "def makeWhiteSquares(window_list):\n",
    "    #Create test window images dict with white square defects\n",
    "    defect_window_list = np.copy(window_list)\n",
    "#Fill defect train window images\n",
    "    for image in defect_window_list:\n",
    "        #Random sized white square (2D array full of ones)\n",
    "        sq_random_x = random.randint(5,25)\n",
    "        sq_random_y = random.randint(5,25)\n",
    "        white_square = np.ones((sq_random_y,sq_random_x))\n",
    "        #Random coordinates for the square\n",
    "        random_x_coord = random.randint(0,window_x-sq_random_x)\n",
    "        random_y_coord = random.randint(0,window_y-sq_random_y)\n",
    "        #Replace the coordinates with white square\n",
    "        image[random_y_coord:random_y_coord + sq_random_y, random_x_coord: random_x_coord + sq_random_x,0] = white_square\n",
    "    return defect_window_list\n",
    "\n",
    "def copyPaste(image):\n",
    "    copied_image = np.copy(image)\n",
    "    #Random sized copy-pasted area (2D array)\n",
    "    sq_random_x = random.randint(5,25)\n",
    "    sq_random_y = random.randint(5,25)\n",
    "    #Random coordinates for the square\n",
    "    random_x_coord = random.randint(0,image.shape[1]-sq_random_x)\n",
    "    random_y_coord = random.randint(0,image.shape[0]-sq_random_y)\n",
    "    #Copy the area\n",
    "    copyArea = image[random_y_coord:random_y_coord + sq_random_y, random_x_coord: random_x_coord + sq_random_x,0]\n",
    "    #Paste coordinates\n",
    "    random_x_coord = random.randint(0,window_x-sq_random_x)\n",
    "    random_y_coord = random.randint(0,window_y-sq_random_y)\n",
    "    #Paste the area\n",
    "    copied_image[random_y_coord:random_y_coord + sq_random_y, random_x_coord: random_x_coord + sq_random_x,0] = copyArea\n",
    "    return copied_image\n",
    "\n",
    "def createLabels(image_list, defect_status):\n",
    "    #Create labels for the images\n",
    "    labels_list = []\n",
    "    for image in image_list:\n",
    "        if defect_status:\n",
    "            labels_list.append(1)\n",
    "        else:\n",
    "            labels_list.append(0)\n",
    "    labels_list = np.array(labels_list)\n",
    "    return labels_list\n",
    "        \n",
    "def shuffleTwoArrays(image_list, label_list):\n",
    "    #Shuffles the image and label arrays in the same way\n",
    "    randomize = np.arange(len(label_list))\n",
    "    np.random.shuffle(randomize)\n",
    "    image_list = image_list[randomize]\n",
    "    label_list = label_list[randomize]\n",
    "    return (image_list, label_list)\n",
    "\n",
    "def generateImages(normal_image_list, num_normal, num_defects):\n",
    "    #A generator that generates images\n",
    "    while True:\n",
    "        generated_images = []\n",
    "        generated_labels = []\n",
    "        for i in range(num_normal):\n",
    "            random_index = random.randint(0,len(normal_image_list)-1)\n",
    "            generated_images.append(normal_image_list[random_index])\n",
    "            generated_labels.append(0)\n",
    "        for i in range(num_defects):\n",
    "            random_index = random.randint(0,len(normal_image_list)-1)\n",
    "            generated_images.append(copyPaste(normal_image_list[random_index]))\n",
    "            generated_labels.append(1)\n",
    "        generated_images = np.array(generated_images)\n",
    "        generated_labels = np.array(generated_labels)\n",
    "        generated_images, generated_labels = shuffleTwoArrays(generated_images, generated_labels)\n",
    "        n = generated_images.shape[0]\n",
    "        yield generated_images, generated_labels.reshape(n, 1)\n",
    "\n",
    "def valGeneratorImages(test_x, test_y, num_desired):\n",
    "    while True:\n",
    "        generated_images = []\n",
    "        generated_labels = []\n",
    "        for i in range(num_normal):\n",
    "            random_index = random.randint(0,len(test_x)-1)\n",
    "            generated_images.append(test_x[random_index])\n",
    "            generated_labels.append(test_y[random_index])\n",
    "        yield generated_images, generated_labels\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b3b7f5bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dictionaries with TEM images\n",
    "f_name = os.path.join(raw_data_dir, 'test_full_arrays')\n",
    "#Dict with test image arrays (each key has a value of an array of numbers between 0 and 1)\n",
    "test_full_arrays = pickle.load(open(f_name, \"rb\"))\n",
    "f_name = os.path.join(raw_data_dir, 'train_full_arrays')\n",
    "#Dict with train image arrays (each key has a value of an array of numbers between 0 and 1)\n",
    "train_full_arrays = pickle.load(open(f_name, \"rb\"))\n",
    "\n",
    "window_x = 118\n",
    "window_y = 84\n",
    "num_windows = 100\n",
    "\n",
    "#Make testing window images and labels\n",
    "test_window_images = makeWindows(test_full_arrays, num_windows, window_x, window_y)\n",
    "test_window_labels = createLabels(test_window_images, False)\n",
    "\n",
    "#Make training window images and labels\n",
    "train_window_images = makeWindows(train_full_arrays, num_windows ,window_x, window_y)\n",
    "train_window_labels = createLabels(train_window_images, False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6a6083f6-8e39-4d73-9290-654eeef03f4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_gen = generateImages(train_window_images, 32, 32)\n",
    "val_gen = generateImages(test_window_images, 512, 512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b65b9723-0e8a-475e-9d95-d77387d8ff99",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_x, val_y =next(val_gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f261ad5e-5139-49d9-85ac-32ce6058e669",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11200, 84, 118, 1)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_window_images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "23f2ee2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_6 (Conv2D)            (None, 82, 116, 8)        80        \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 82, 116, 8)        32        \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 82, 116, 8)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 41, 58, 8)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 39, 56, 16)        1168      \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 39, 56, 16)        64        \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 39, 56, 16)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 19, 28, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 17, 26, 32)        4640      \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 17, 26, 32)        128       \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 17, 26, 32)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2 (None, 8, 13, 32)         0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 3328)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 32)                106528    \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 33        \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 112,673\n",
      "Trainable params: 112,561\n",
      "Non-trainable params: 112\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "#Stuff\n",
    "filters = 32\n",
    "filter_size = 3\n",
    "pool_size = 2\n",
    "epoch_number = 50\n",
    "my_models = []\n",
    "my_val_accuracy = []\n",
    "my_val_loss = []\n",
    "\n",
    "# Build the model.\n",
    "train_gen = generateImages(train_window_images, 32, 32)\n",
    "val_gen = generateImages(test_window_images, 32, 32)\n",
    "# print(f'4 Layers Results: ')\n",
    "# model = Sequential([\n",
    "#   Conv2D(filters, filter_size, input_shape = (84, 118, 1)), \n",
    "#   MaxPooling2D(pool_size = pool_size),\n",
    "#   Conv2D(filters * 2, filter_size),\n",
    "#   MaxPooling2D(pool_size = pool_size),\n",
    "#   Conv2D(filters * 4, filter_size),\n",
    "#   MaxPooling2D(pool_size = pool_size),\n",
    "#   Conv2D(filters * 8, filter_size),\n",
    "#   MaxPooling2D(pool_size = pool_size),\n",
    "#   Flatten(),\n",
    "#   Dense(2, activation = 'sigmoid')\n",
    "# ])\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(8, (3, 3), input_shape=(84, 118, 1)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(16, (3, 3)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(32, (3, 3)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Flatten())  # this converts our 3D feature maps to 1D feature vectors\n",
    "model.add(Dense(32))\n",
    "#     model.add(Dropout(0.5))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dense(1))\n",
    "model.add(Activation('sigmoid'))\n",
    "\n",
    "# Compile the model.\n",
    "model.compile(loss='binary_crossentropy',\n",
    "                  optimizer='nadam',\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc22809e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "175/175 [==============================] - 38s 214ms/step - loss: 0.7138 - accuracy: 0.5470 - val_loss: 0.7410 - val_accuracy: 0.5000\n",
      "Epoch 2/200\n",
      "175/175 [==============================] - 37s 212ms/step - loss: 0.3080 - accuracy: 0.8688 - val_loss: 0.9103 - val_accuracy: 0.5674\n",
      "Epoch 3/200\n",
      "175/175 [==============================] - 37s 212ms/step - loss: 0.0950 - accuracy: 0.9696 - val_loss: 0.3540 - val_accuracy: 0.8535\n",
      "Epoch 4/200\n",
      "175/175 [==============================] - 37s 212ms/step - loss: 0.0537 - accuracy: 0.9840 - val_loss: 0.1042 - val_accuracy: 0.9648\n",
      "Epoch 5/200\n",
      "175/175 [==============================] - 37s 212ms/step - loss: 0.0429 - accuracy: 0.9881 - val_loss: 0.0938 - val_accuracy: 0.9678\n",
      "Epoch 6/200\n",
      "175/175 [==============================] - 37s 213ms/step - loss: 0.0399 - accuracy: 0.9890 - val_loss: 0.0914 - val_accuracy: 0.9707\n",
      "Epoch 7/200\n",
      "175/175 [==============================] - 37s 213ms/step - loss: 0.0334 - accuracy: 0.9920 - val_loss: 0.1030 - val_accuracy: 0.9717\n",
      "Epoch 8/200\n",
      "175/175 [==============================] - 37s 212ms/step - loss: 0.0299 - accuracy: 0.9925 - val_loss: 0.0175 - val_accuracy: 0.9971\n",
      "Epoch 9/200\n",
      "175/175 [==============================] - 37s 213ms/step - loss: 0.0337 - accuracy: 0.9913 - val_loss: 0.0290 - val_accuracy: 0.9912\n",
      "Epoch 10/200\n",
      "175/175 [==============================] - 37s 212ms/step - loss: 0.0261 - accuracy: 0.9937 - val_loss: 0.0205 - val_accuracy: 0.9961\n",
      "Epoch 11/200\n",
      "175/175 [==============================] - 37s 211ms/step - loss: 0.0232 - accuracy: 0.9944 - val_loss: 0.0299 - val_accuracy: 0.9932\n",
      "Epoch 12/200\n",
      "175/175 [==============================] - 37s 212ms/step - loss: 0.0264 - accuracy: 0.9946 - val_loss: 0.0160 - val_accuracy: 0.9980\n",
      "Epoch 13/200\n",
      "175/175 [==============================] - 38s 215ms/step - loss: 0.0231 - accuracy: 0.9954 - val_loss: 0.0210 - val_accuracy: 0.9961\n",
      "Epoch 14/200\n",
      "175/175 [==============================] - 38s 215ms/step - loss: 0.0257 - accuracy: 0.9941 - val_loss: 0.0110 - val_accuracy: 0.9990\n",
      "Epoch 15/200\n",
      "175/175 [==============================] - 37s 214ms/step - loss: 0.0199 - accuracy: 0.9950 - val_loss: 0.0147 - val_accuracy: 0.9980\n",
      "Epoch 16/200\n",
      "175/175 [==============================] - 38s 214ms/step - loss: 0.0257 - accuracy: 0.9949 - val_loss: 0.0363 - val_accuracy: 0.9971\n",
      "Epoch 17/200\n",
      "175/175 [==============================] - 38s 215ms/step - loss: 0.0192 - accuracy: 0.9961 - val_loss: 0.0366 - val_accuracy: 0.9883\n",
      "Epoch 18/200\n",
      "175/175 [==============================] - 38s 215ms/step - loss: 0.0209 - accuracy: 0.9953 - val_loss: 0.0275 - val_accuracy: 0.9932\n",
      "Epoch 19/200\n",
      "175/175 [==============================] - 37s 212ms/step - loss: 0.0193 - accuracy: 0.9960 - val_loss: 0.0081 - val_accuracy: 0.9990\n",
      "Epoch 20/200\n",
      "175/175 [==============================] - 37s 213ms/step - loss: 0.0179 - accuracy: 0.9962 - val_loss: 0.0170 - val_accuracy: 0.9961\n",
      "Epoch 21/200\n",
      "175/175 [==============================] - 37s 213ms/step - loss: 0.0205 - accuracy: 0.9956 - val_loss: 0.0120 - val_accuracy: 1.0000\n",
      "Epoch 22/200\n",
      "175/175 [==============================] - 37s 212ms/step - loss: 0.0181 - accuracy: 0.9964 - val_loss: 0.0106 - val_accuracy: 0.9980\n",
      "Epoch 23/200\n",
      "175/175 [==============================] - 37s 213ms/step - loss: 0.0227 - accuracy: 0.9955 - val_loss: 0.0105 - val_accuracy: 0.9980\n",
      "Epoch 24/200\n",
      "175/175 [==============================] - 37s 213ms/step - loss: 0.0172 - accuracy: 0.9968 - val_loss: 0.0067 - val_accuracy: 0.9980\n",
      "Epoch 25/200\n",
      "175/175 [==============================] - 37s 212ms/step - loss: 0.0178 - accuracy: 0.9963 - val_loss: 0.0032 - val_accuracy: 1.0000\n",
      "Epoch 26/200\n",
      "175/175 [==============================] - 38s 215ms/step - loss: 0.0191 - accuracy: 0.9967 - val_loss: 0.0038 - val_accuracy: 1.0000\n",
      "Epoch 27/200\n",
      "175/175 [==============================] - 37s 214ms/step - loss: 0.0217 - accuracy: 0.9956 - val_loss: 0.0090 - val_accuracy: 0.9971\n",
      "Epoch 28/200\n",
      "175/175 [==============================] - 38s 214ms/step - loss: 0.0160 - accuracy: 0.9968 - val_loss: 0.0195 - val_accuracy: 0.9971\n",
      "Epoch 29/200\n",
      "175/175 [==============================] - 37s 214ms/step - loss: 0.0163 - accuracy: 0.9969 - val_loss: 0.0093 - val_accuracy: 0.9980\n",
      "Epoch 30/200\n",
      "175/175 [==============================] - 37s 213ms/step - loss: 0.0208 - accuracy: 0.9955 - val_loss: 0.0353 - val_accuracy: 0.9932\n",
      "Epoch 31/200\n",
      "175/175 [==============================] - 36s 208ms/step - loss: 0.0160 - accuracy: 0.9968 - val_loss: 0.0106 - val_accuracy: 0.9990\n",
      "Epoch 32/200\n",
      "175/175 [==============================] - 37s 210ms/step - loss: 0.0186 - accuracy: 0.9962 - val_loss: 0.0085 - val_accuracy: 0.9990\n",
      "Epoch 33/200\n",
      "175/175 [==============================] - 37s 211ms/step - loss: 0.0145 - accuracy: 0.9973 - val_loss: 0.0023 - val_accuracy: 0.9990\n",
      "Epoch 34/200\n",
      "175/175 [==============================] - 37s 210ms/step - loss: 0.0143 - accuracy: 0.9972 - val_loss: 0.0134 - val_accuracy: 0.9980\n",
      "Epoch 35/200\n",
      "175/175 [==============================] - 37s 212ms/step - loss: 0.0146 - accuracy: 0.9975 - val_loss: 0.0055 - val_accuracy: 0.9990\n",
      "Epoch 36/200\n",
      "175/175 [==============================] - 37s 213ms/step - loss: 0.0225 - accuracy: 0.9956 - val_loss: 0.0058 - val_accuracy: 0.9990\n",
      "Epoch 37/200\n",
      "175/175 [==============================] - 37s 213ms/step - loss: 0.0187 - accuracy: 0.9962 - val_loss: 0.0056 - val_accuracy: 0.9990\n",
      "Epoch 38/200\n",
      "175/175 [==============================] - 37s 213ms/step - loss: 0.0175 - accuracy: 0.9966 - val_loss: 0.0208 - val_accuracy: 0.9980\n",
      "Epoch 39/200\n",
      "175/175 [==============================] - 37s 214ms/step - loss: 0.0131 - accuracy: 0.9976 - val_loss: 0.0074 - val_accuracy: 0.9980\n",
      "Epoch 40/200\n",
      "175/175 [==============================] - 37s 213ms/step - loss: 0.0180 - accuracy: 0.9967 - val_loss: 0.0029 - val_accuracy: 0.9990\n",
      "Epoch 41/200\n",
      "175/175 [==============================] - 37s 212ms/step - loss: 0.0136 - accuracy: 0.9973 - val_loss: 0.0071 - val_accuracy: 0.9990\n",
      "Epoch 42/200\n",
      "175/175 [==============================] - 37s 213ms/step - loss: 0.0165 - accuracy: 0.9971 - val_loss: 0.0092 - val_accuracy: 0.9990\n",
      "Epoch 43/200\n",
      "175/175 [==============================] - 37s 214ms/step - loss: 0.0210 - accuracy: 0.9964 - val_loss: 0.0172 - val_accuracy: 0.9980\n",
      "Epoch 44/200\n",
      "175/175 [==============================] - 37s 212ms/step - loss: 0.0190 - accuracy: 0.9965 - val_loss: 0.0070 - val_accuracy: 0.9990\n",
      "Epoch 45/200\n",
      "175/175 [==============================] - 38s 215ms/step - loss: 0.0129 - accuracy: 0.9978 - val_loss: 0.0020 - val_accuracy: 1.0000\n",
      "Epoch 46/200\n",
      "175/175 [==============================] - 37s 211ms/step - loss: 0.0162 - accuracy: 0.9972 - val_loss: 0.0032 - val_accuracy: 0.9990\n",
      "Epoch 47/200\n",
      "175/175 [==============================] - 37s 212ms/step - loss: 0.0172 - accuracy: 0.9971 - val_loss: 0.0107 - val_accuracy: 0.9990\n",
      "Epoch 48/200\n",
      "175/175 [==============================] - 37s 213ms/step - loss: 0.0186 - accuracy: 0.9963 - val_loss: 0.0073 - val_accuracy: 0.9990\n",
      "Epoch 49/200\n",
      "175/175 [==============================] - 37s 211ms/step - loss: 0.0170 - accuracy: 0.9966 - val_loss: 0.0023 - val_accuracy: 1.0000\n",
      "Epoch 50/200\n",
      "175/175 [==============================] - 37s 212ms/step - loss: 0.0145 - accuracy: 0.9976 - val_loss: 0.1826 - val_accuracy: 0.9863\n",
      "Epoch 51/200\n",
      "175/175 [==============================] - 37s 212ms/step - loss: 0.0187 - accuracy: 0.9965 - val_loss: 0.0060 - val_accuracy: 1.0000\n",
      "Epoch 52/200\n",
      "175/175 [==============================] - 37s 211ms/step - loss: 0.0156 - accuracy: 0.9968 - val_loss: 0.0027 - val_accuracy: 1.0000\n",
      "Epoch 53/200\n",
      "175/175 [==============================] - 37s 211ms/step - loss: 0.0193 - accuracy: 0.9965 - val_loss: 0.0050 - val_accuracy: 0.9990\n",
      "Epoch 54/200\n",
      "175/175 [==============================] - 37s 211ms/step - loss: 0.0164 - accuracy: 0.9969 - val_loss: 0.0025 - val_accuracy: 1.0000\n",
      "Epoch 55/200\n",
      "175/175 [==============================] - 37s 211ms/step - loss: 0.0114 - accuracy: 0.9979 - val_loss: 0.0134 - val_accuracy: 0.9990\n",
      "Epoch 56/200\n",
      "175/175 [==============================] - 37s 212ms/step - loss: 0.0193 - accuracy: 0.9962 - val_loss: 0.0245 - val_accuracy: 0.9951\n",
      "Epoch 57/200\n",
      "175/175 [==============================] - 37s 211ms/step - loss: 0.0135 - accuracy: 0.9973 - val_loss: 0.0047 - val_accuracy: 1.0000\n",
      "Epoch 58/200\n",
      "175/175 [==============================] - 37s 211ms/step - loss: 0.0202 - accuracy: 0.9962 - val_loss: 0.0016 - val_accuracy: 1.0000\n",
      "Epoch 59/200\n",
      "175/175 [==============================] - 37s 212ms/step - loss: 0.0136 - accuracy: 0.9975 - val_loss: 0.0166 - val_accuracy: 0.9961\n",
      "Epoch 60/200\n",
      "175/175 [==============================] - 37s 212ms/step - loss: 0.0172 - accuracy: 0.9971 - val_loss: 0.0066 - val_accuracy: 1.0000\n",
      "Epoch 61/200\n",
      "175/175 [==============================] - 37s 212ms/step - loss: 0.0131 - accuracy: 0.9979 - val_loss: 0.0077 - val_accuracy: 0.9990\n",
      "Epoch 62/200\n",
      "175/175 [==============================] - 37s 211ms/step - loss: 0.0149 - accuracy: 0.9973 - val_loss: 0.0012 - val_accuracy: 1.0000\n",
      "Epoch 63/200\n",
      "175/175 [==============================] - 37s 212ms/step - loss: 0.0116 - accuracy: 0.9980 - val_loss: 0.0013 - val_accuracy: 1.0000\n",
      "Epoch 64/200\n",
      "175/175 [==============================] - 37s 210ms/step - loss: 0.0155 - accuracy: 0.9974 - val_loss: 0.0032 - val_accuracy: 1.0000\n",
      "Epoch 65/200\n",
      "175/175 [==============================] - 37s 210ms/step - loss: 0.0146 - accuracy: 0.9975 - val_loss: 0.0106 - val_accuracy: 0.9990\n",
      "Epoch 66/200\n",
      "175/175 [==============================] - 37s 212ms/step - loss: 0.0154 - accuracy: 0.9973 - val_loss: 0.0050 - val_accuracy: 1.0000\n",
      "Epoch 67/200\n",
      "175/175 [==============================] - 37s 211ms/step - loss: 0.0178 - accuracy: 0.9967 - val_loss: 0.0082 - val_accuracy: 0.9990\n",
      "Epoch 68/200\n",
      "175/175 [==============================] - 37s 212ms/step - loss: 0.0150 - accuracy: 0.9977 - val_loss: 0.0012 - val_accuracy: 1.0000\n",
      "Epoch 69/200\n",
      "175/175 [==============================] - 37s 212ms/step - loss: 0.0134 - accuracy: 0.9979 - val_loss: 0.0015 - val_accuracy: 1.0000\n",
      "Epoch 70/200\n",
      "175/175 [==============================] - 37s 212ms/step - loss: 0.0106 - accuracy: 0.9983 - val_loss: 0.0013 - val_accuracy: 1.0000\n",
      "Epoch 71/200\n",
      "175/175 [==============================] - 37s 212ms/step - loss: 0.0147 - accuracy: 0.9976 - val_loss: 0.0025 - val_accuracy: 1.0000\n",
      "Epoch 72/200\n",
      "175/175 [==============================] - 37s 211ms/step - loss: 0.0157 - accuracy: 0.9974 - val_loss: 0.0315 - val_accuracy: 0.9941\n",
      "Epoch 73/200\n",
      "175/175 [==============================] - 37s 214ms/step - loss: 0.0169 - accuracy: 0.9970 - val_loss: 0.0028 - val_accuracy: 0.9990\n",
      "Epoch 74/200\n",
      "175/175 [==============================] - 37s 213ms/step - loss: 0.0122 - accuracy: 0.9976 - val_loss: 0.0087 - val_accuracy: 0.9990\n",
      "Epoch 75/200\n",
      "175/175 [==============================] - 37s 214ms/step - loss: 0.0144 - accuracy: 0.9976 - val_loss: 0.0146 - val_accuracy: 0.9961\n",
      "Epoch 76/200\n",
      "175/175 [==============================] - 37s 214ms/step - loss: 0.0163 - accuracy: 0.9975 - val_loss: 0.0128 - val_accuracy: 0.9990\n",
      "Epoch 77/200\n",
      "175/175 [==============================] - 37s 213ms/step - loss: 0.0145 - accuracy: 0.9971 - val_loss: 0.0348 - val_accuracy: 0.9902\n",
      "Epoch 78/200\n",
      "175/175 [==============================] - 37s 213ms/step - loss: 0.0244 - accuracy: 0.9957 - val_loss: 0.0908 - val_accuracy: 0.9951\n",
      "Epoch 79/200\n",
      "175/175 [==============================] - 37s 213ms/step - loss: 0.0144 - accuracy: 0.9976 - val_loss: 0.0237 - val_accuracy: 0.9990\n",
      "Epoch 80/200\n",
      "175/175 [==============================] - 37s 213ms/step - loss: 0.0201 - accuracy: 0.9963 - val_loss: 0.0030 - val_accuracy: 1.0000\n",
      "Epoch 81/200\n",
      "175/175 [==============================] - 37s 214ms/step - loss: 0.0165 - accuracy: 0.9970 - val_loss: 0.0016 - val_accuracy: 1.0000\n",
      "Epoch 82/200\n",
      "175/175 [==============================] - 37s 213ms/step - loss: 0.0145 - accuracy: 0.9976 - val_loss: 0.0068 - val_accuracy: 1.0000\n",
      "Epoch 83/200\n",
      "175/175 [==============================] - 37s 214ms/step - loss: 0.0126 - accuracy: 0.9977 - val_loss: 0.0028 - val_accuracy: 0.9990\n",
      "Epoch 84/200\n",
      "175/175 [==============================] - 37s 213ms/step - loss: 0.0082 - accuracy: 0.9987 - val_loss: 0.0021 - val_accuracy: 1.0000\n",
      "Epoch 85/200\n",
      "175/175 [==============================] - 37s 212ms/step - loss: 0.0173 - accuracy: 0.9971 - val_loss: 0.0039 - val_accuracy: 1.0000\n",
      "Epoch 86/200\n",
      "175/175 [==============================] - 37s 213ms/step - loss: 0.0086 - accuracy: 0.9987 - val_loss: 0.0041 - val_accuracy: 0.9990\n",
      "Epoch 87/200\n",
      "175/175 [==============================] - 37s 212ms/step - loss: 0.0172 - accuracy: 0.9971 - val_loss: 0.0093 - val_accuracy: 0.9990\n",
      "Epoch 88/200\n",
      "175/175 [==============================] - 37s 213ms/step - loss: 0.0120 - accuracy: 0.9979 - val_loss: 0.0122 - val_accuracy: 0.9990\n",
      "Epoch 89/200\n",
      "175/175 [==============================] - 37s 213ms/step - loss: 0.0109 - accuracy: 0.9982 - val_loss: 0.0091 - val_accuracy: 0.9990\n",
      "Epoch 90/200\n",
      "175/175 [==============================] - 38s 214ms/step - loss: 0.0163 - accuracy: 0.9971 - val_loss: 0.0052 - val_accuracy: 0.9990\n",
      "Epoch 91/200\n",
      "175/175 [==============================] - 37s 213ms/step - loss: 0.0160 - accuracy: 0.9972 - val_loss: 0.0020 - val_accuracy: 1.0000\n",
      "Epoch 92/200\n",
      "175/175 [==============================] - 37s 213ms/step - loss: 0.0129 - accuracy: 0.9979 - val_loss: 0.0031 - val_accuracy: 1.0000\n",
      "Epoch 93/200\n",
      "175/175 [==============================] - 37s 213ms/step - loss: 0.0105 - accuracy: 0.9981 - val_loss: 0.0066 - val_accuracy: 0.9990\n",
      "Epoch 94/200\n",
      "175/175 [==============================] - 37s 214ms/step - loss: 0.0163 - accuracy: 0.9973 - val_loss: 0.0039 - val_accuracy: 1.0000\n",
      "Epoch 95/200\n",
      "175/175 [==============================] - 37s 214ms/step - loss: 0.0087 - accuracy: 0.9986 - val_loss: 0.0025 - val_accuracy: 1.0000\n",
      "Epoch 96/200\n",
      "175/175 [==============================] - 37s 213ms/step - loss: 0.0171 - accuracy: 0.9968 - val_loss: 0.0080 - val_accuracy: 0.9990\n",
      "Epoch 97/200\n",
      "175/175 [==============================] - 37s 212ms/step - loss: 0.0147 - accuracy: 0.9976 - val_loss: 0.0145 - val_accuracy: 0.9961\n",
      "Epoch 98/200\n",
      "175/175 [==============================] - 37s 212ms/step - loss: 0.0143 - accuracy: 0.9975 - val_loss: 0.0013 - val_accuracy: 1.0000\n",
      "Epoch 99/200\n",
      "175/175 [==============================] - 37s 213ms/step - loss: 0.0139 - accuracy: 0.9975 - val_loss: 0.0021 - val_accuracy: 1.0000\n",
      "Epoch 100/200\n",
      "175/175 [==============================] - 37s 213ms/step - loss: 0.0163 - accuracy: 0.9971 - val_loss: 0.0122 - val_accuracy: 0.9990\n",
      "Epoch 101/200\n",
      "175/175 [==============================] - 37s 213ms/step - loss: 0.0141 - accuracy: 0.9971 - val_loss: 0.0074 - val_accuracy: 0.9971\n",
      "Epoch 102/200\n",
      "175/175 [==============================] - 37s 213ms/step - loss: 0.0160 - accuracy: 0.9973 - val_loss: 0.0085 - val_accuracy: 1.0000\n",
      "Epoch 103/200\n",
      "175/175 [==============================] - 37s 214ms/step - loss: 0.0123 - accuracy: 0.9981 - val_loss: 0.0372 - val_accuracy: 0.9941\n",
      "Epoch 104/200\n",
      "175/175 [==============================] - 37s 213ms/step - loss: 0.0093 - accuracy: 0.9985 - val_loss: 0.0100 - val_accuracy: 0.9980\n",
      "Epoch 105/200\n",
      "175/175 [==============================] - 37s 213ms/step - loss: 0.0152 - accuracy: 0.9972 - val_loss: 9.7849e-04 - val_accuracy: 1.0000\n",
      "Epoch 106/200\n",
      "175/175 [==============================] - 37s 212ms/step - loss: 0.0146 - accuracy: 0.9975 - val_loss: 0.0070 - val_accuracy: 0.9980\n",
      "Epoch 107/200\n",
      "175/175 [==============================] - 37s 213ms/step - loss: 0.0140 - accuracy: 0.9979 - val_loss: 0.0024 - val_accuracy: 1.0000\n",
      "Epoch 108/200\n",
      "175/175 [==============================] - 37s 212ms/step - loss: 0.0102 - accuracy: 0.9983 - val_loss: 0.0097 - val_accuracy: 0.9971\n",
      "Epoch 109/200\n",
      "175/175 [==============================] - 37s 213ms/step - loss: 0.0127 - accuracy: 0.9980 - val_loss: 0.0020 - val_accuracy: 1.0000\n",
      "Epoch 110/200\n",
      "175/175 [==============================] - 37s 212ms/step - loss: 0.0140 - accuracy: 0.9977 - val_loss: 0.0035 - val_accuracy: 1.0000\n",
      "Epoch 111/200\n",
      "175/175 [==============================] - 37s 213ms/step - loss: 0.0119 - accuracy: 0.9981 - val_loss: 0.0031 - val_accuracy: 1.0000\n",
      "Epoch 112/200\n",
      "175/175 [==============================] - 37s 213ms/step - loss: 0.0118 - accuracy: 0.9981 - val_loss: 0.0040 - val_accuracy: 0.9990\n",
      "Epoch 113/200\n",
      "175/175 [==============================] - 37s 214ms/step - loss: 0.0112 - accuracy: 0.9981 - val_loss: 0.0666 - val_accuracy: 0.9893\n",
      "Epoch 114/200\n",
      "175/175 [==============================] - 37s 214ms/step - loss: 0.0132 - accuracy: 0.9979 - val_loss: 0.0332 - val_accuracy: 0.9951\n",
      "Epoch 115/200\n",
      "175/175 [==============================] - 37s 214ms/step - loss: 0.0150 - accuracy: 0.9974 - val_loss: 0.0070 - val_accuracy: 0.9980\n",
      "Epoch 116/200\n",
      "175/175 [==============================] - 38s 215ms/step - loss: 0.0134 - accuracy: 0.9979 - val_loss: 0.0020 - val_accuracy: 1.0000\n",
      "Epoch 117/200\n",
      "175/175 [==============================] - 37s 213ms/step - loss: 0.0095 - accuracy: 0.9985 - val_loss: 0.0085 - val_accuracy: 0.9980\n",
      "Epoch 118/200\n",
      "175/175 [==============================] - 37s 213ms/step - loss: 0.0224 - accuracy: 0.9957 - val_loss: 0.0055 - val_accuracy: 0.9990\n",
      "Epoch 119/200\n",
      "175/175 [==============================] - 37s 214ms/step - loss: 0.0122 - accuracy: 0.9979 - val_loss: 0.0023 - val_accuracy: 1.0000\n",
      "Epoch 120/200\n",
      "175/175 [==============================] - 38s 214ms/step - loss: 0.0147 - accuracy: 0.9971 - val_loss: 0.0053 - val_accuracy: 1.0000\n",
      "Epoch 121/200\n",
      "175/175 [==============================] - 37s 213ms/step - loss: 0.0096 - accuracy: 0.9987 - val_loss: 0.0021 - val_accuracy: 1.0000\n",
      "Epoch 122/200\n",
      "175/175 [==============================] - 38s 215ms/step - loss: 0.0192 - accuracy: 0.9969 - val_loss: 0.0021 - val_accuracy: 1.0000\n",
      "Epoch 123/200\n",
      " 50/175 [=======>......................] - ETA: 26s - loss: 0.0123 - accuracy: 0.9981"
     ]
    }
   ],
   "source": [
    "# Train the model.\n",
    "# history = model.fit(\n",
    "#   train_gen,\n",
    "#   validation_data = val_gen,\n",
    "#   epochs = epoch_number,\n",
    "#   steps_per_epoch=11200/64,\n",
    "#   validation_steps = 11200/64\n",
    "# )\n",
    "\n",
    "# Fit model\n",
    "history = model.fit(\n",
    "    x = train_gen,\n",
    "    epochs=200,\n",
    "    steps_per_epoch=len(train_window_images)//64,\n",
    "    validation_data=(val_x, val_y),\n",
    "    validation_batch_size=int(len(val_x)*0.50))\n",
    "\n",
    "my_models.append(model)\n",
    "my_val_accuracy.append(history.history['val_accuracy'][-1])\n",
    "my_val_loss.append(history.history['val_loss'][-1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4ca7bd7-da7a-4e24-af11-0e2703ea2dd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(os.path.join(notebooks_dir, 'cutpaste_200epochs.SavedModel'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a18a4f7-c08e-4af2-8153-bec6a4217678",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(\n",
    "    x = train_gen,\n",
    "    epochs=800,\n",
    "    steps_per_epoch=len(train_window_images)//64,\n",
    "    validation_data=(val_x, val_y),\n",
    "    validation_batch_size=int(len(val_x)*0.50))\n",
    "\n",
    "model.save(os.path.join(notebooks_dir, 'cutpaste_1000epochs.SavedModel'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50a56bd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Predict on the first 5 test images.\n",
    "predictions = model.predict(test_window_images[:5])\n",
    "\n",
    "# Print our model's predictions.\n",
    "print(\"Predictions\")\n",
    "print(np.argmax(predictions, axis=1))\n",
    "\n",
    "# Check our predictions against the ground truths.\n",
    "print(\"Real Labels\")\n",
    "print(test_window_labels[:5])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
